{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Marketplace-Orders-Ingestion\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n"
      ],
      "metadata": {
        "id": "Mycre4rOhybs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Raw orders data provided\n",
        "orders_data = [\n",
        "    (\"ORD001\",\"C001\",\"Delhi \",\"Electronics\",\"Laptop\",\"45000\",\"2024-01-05\",\"Completed\"),\n",
        "    (\"ORD002\",\"C002\",\"Mumbai\",\"Electronics\",\"Mobile \",\"32000\",\"05/01/2024\",\"Completed\"),\n",
        "    (\"ORD003\",\"C003\",\"Bangalore\",\"Electronics\",\"Tablet\",\"30000\",\"2024/01/06\",\"Completed\"),\n",
        "    (\"ORD004\",\"C004\",\"Delhi\",\"Electronics\",\"Laptop\",\"\",\"2024-01-07\",\"Cancelled\"),\n",
        "    (\"ORD005\",\"C005\",\"Chennai\",\"Electronics\",\"Mobile\",\"invalid\",\"2024-01-08\",\"Completed\"),\n",
        "    (\"ORD006\",\"C006\",\"Mumbai\",\"Home\",\"Mixer\",None,\"2024-01-08\",\"Completed\"),\n",
        "    (\"ORD007\",\"C001\",\"Delhi\",\"Electronics\",\"Laptop\",\"47000\",\"09-01-2024\",\"Completed\"),\n",
        "    (\"ORD008\",\"C007\",\"Bangalore\",\"Home\",\"Vacuum\",\"28000\",\"2024-01-09\",\"Completed\"),\n",
        "    (\"ORD009\",\"C002\",\"Mumbai\",\"Electronics\",\"Laptop\",\"55000\",\"2024-01-10\",\"Completed\"),\n",
        "    (\"ORD010\",\"C008\",\"Delhi\",\"Home\",\"AirPurifier\",\"38000\",\"2024-01-10\",\"Completed\"),\n",
        "    (\"ORD011\",\"C009\",\"Mumbai\",\"Home\",\"Vacuum\",\"29000\",\"2024-01-11\",\"Completed\"),\n",
        "    (\"ORD012\",\"C010\",\"Bangalore\",\"Electronics\",\"Mobile\",\"33000\",\"2024-01-11\",\"Completed\"),\n",
        "    (\"ORD013\",\"C003\",\"Bangalore\",\"Home\",\"Mixer\",\"21000\",\"2024-01-12\",\"Completed\"),\n",
        "    (\"ORD014\",\"C004\",\"Delhi\",\"Electronics\",\"Tablet\",\"26000\",\"2024-01-12\",\"Completed\"),\n",
        "    (\"ORD015\",\"C005\",\"Chennai\",\"Electronics\",\"Laptop\",\"62000\",\"2024-01-13\",\"Completed\"),\n",
        "    (\"ORD016\",\"C006\",\"Mumbai\",\"Home\",\"AirPurifier\",\"40000\",\"2024-01-13\",\"Completed\"),\n",
        "    (\"ORD017\",\"C007\",\"Bangalore\",\"Electronics\",\"Laptop\",\"51000\",\"2024-01-14\",\"Completed\"),\n",
        "    (\"ORD018\",\"C008\",\"Delhi\",\"Home\",\"Vacuum\",\"31000\",\"2024-01-14\",\"Completed\"),\n",
        "    (\"ORD019\",\"C009\",\"Mumbai\",\"Electronics\",\"Tablet\",\"29000\",\"2024-01-15\",\"Completed\"),\n",
        "    (\"ORD020\",\"C010\",\"Bangalore\",\"Electronics\",\"Laptop\",\"54000\",\"2024-01-15\",\"Completed\"),\n",
        "    (\"ORD020\",\"C010\",\"Bangalore\",\"Electronics\",\"Laptop\",\"54000\",\"2024-01-15\",\"Completed\")\n",
        "]\n"
      ],
      "metadata": {
        "id": "ISNuGvBOh2Ol"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jWmyeAozhEPC"
      },
      "outputs": [],
      "source": [
        "#Define an explicit schema\n",
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "\n",
        "orders_schema = StructType([\n",
        "    StructField(\"order_id\",   StringType(), True),\n",
        "    StructField(\"customer_id\",StringType(), True),\n",
        "    StructField(\"city\",       StringType(), True),\n",
        "    StructField(\"category\",   StringType(), True),\n",
        "    StructField(\"product\",    StringType(), True),\n",
        "    StructField(\"amount\",     StringType(), True),\n",
        "    StructField(\"order_date\", StringType(), True),\n",
        "    StructField(\"status\",     StringType(), True)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a DataFrame using the schema\n",
        "raw_df = spark.createDataFrame(orders_data, schema=orders_schema)"
      ],
      "metadata": {
        "id": "FuSyyKnSh7L-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print and verify schema\n",
        "raw_df.printSchema()\n",
        "# Expected: all StringType\n",
        "\n",
        "print(\"Raw record count:\", raw_df.count())\n",
        "raw_df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YE19PiSh94E",
        "outputId": "1987de60-8432-4344-86aa-35a715581ca0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: string (nullable = true)\n",
            " |-- order_date: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n",
            "Raw record count: 21\n",
            "+--------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "|order_id|customer_id|city     |category   |product    |amount |order_date|status   |\n",
            "+--------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "|ORD001  |C001       |Delhi    |Electronics|Laptop     |45000  |2024-01-05|Completed|\n",
            "|ORD002  |C002       |Mumbai   |Electronics|Mobile     |32000  |05/01/2024|Completed|\n",
            "|ORD003  |C003       |Bangalore|Electronics|Tablet     |30000  |2024/01/06|Completed|\n",
            "|ORD004  |C004       |Delhi    |Electronics|Laptop     |       |2024-01-07|Cancelled|\n",
            "|ORD005  |C005       |Chennai  |Electronics|Mobile     |invalid|2024-01-08|Completed|\n",
            "|ORD006  |C006       |Mumbai   |Home       |Mixer      |NULL   |2024-01-08|Completed|\n",
            "|ORD007  |C001       |Delhi    |Electronics|Laptop     |47000  |09-01-2024|Completed|\n",
            "|ORD008  |C007       |Bangalore|Home       |Vacuum     |28000  |2024-01-09|Completed|\n",
            "|ORD009  |C002       |Mumbai   |Electronics|Laptop     |55000  |2024-01-10|Completed|\n",
            "|ORD010  |C008       |Delhi    |Home       |AirPurifier|38000  |2024-01-10|Completed|\n",
            "|ORD011  |C009       |Mumbai   |Home       |Vacuum     |29000  |2024-01-11|Completed|\n",
            "|ORD012  |C010       |Bangalore|Electronics|Mobile     |33000  |2024-01-11|Completed|\n",
            "|ORD013  |C003       |Bangalore|Home       |Mixer      |21000  |2024-01-12|Completed|\n",
            "|ORD014  |C004       |Delhi    |Electronics|Tablet     |26000  |2024-01-12|Completed|\n",
            "|ORD015  |C005       |Chennai  |Electronics|Laptop     |62000  |2024-01-13|Completed|\n",
            "|ORD016  |C006       |Mumbai   |Home       |AirPurifier|40000  |2024-01-13|Completed|\n",
            "|ORD017  |C007       |Bangalore|Electronics|Laptop     |51000  |2024-01-14|Completed|\n",
            "|ORD018  |C008       |Delhi    |Home       |Vacuum     |31000  |2024-01-14|Completed|\n",
            "|ORD019  |C009       |Mumbai   |Electronics|Tablet     |29000  |2024-01-15|Completed|\n",
            "|ORD020  |C010       |Bangalore|Electronics|Laptop     |54000  |2024-01-15|Completed|\n",
            "+--------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# PHASE 2 — DATA CLEANING\n",
        "# -----------------------\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import (\n",
        "    col, trim, lower, initcap, regexp_replace, when, to_date, coalesce, length\n",
        ")\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "\n",
        "df = raw_df\n"
      ],
      "metadata": {
        "id": "CDMif_a7jWus"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#task4\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import col, trim\n",
        "\n",
        "df_q4 = raw_df\n",
        "\n",
        "string_cols = [f.name for f in df_q4.schema.fields if isinstance(f.dataType, StringType)]\n",
        "df_q4 = df_q4.select([trim(col(c)).alias(c) if c in string_cols else col(c) for c in df_q4.columns])\n",
        "\n",
        "df_q4.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1c-lEqxjsuQ",
        "outputId": "aa38c9ae-d54f-4486-829e-5b2f96e45723"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "|order_id|customer_id|city     |category   |product    |amount |order_date|status   |\n",
            "+--------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "|ORD001  |C001       |Delhi    |Electronics|Laptop     |45000  |2024-01-05|Completed|\n",
            "|ORD002  |C002       |Mumbai   |Electronics|Mobile     |32000  |05/01/2024|Completed|\n",
            "|ORD003  |C003       |Bangalore|Electronics|Tablet     |30000  |2024/01/06|Completed|\n",
            "|ORD004  |C004       |Delhi    |Electronics|Laptop     |       |2024-01-07|Cancelled|\n",
            "|ORD005  |C005       |Chennai  |Electronics|Mobile     |invalid|2024-01-08|Completed|\n",
            "|ORD006  |C006       |Mumbai   |Home       |Mixer      |NULL   |2024-01-08|Completed|\n",
            "|ORD007  |C001       |Delhi    |Electronics|Laptop     |47000  |09-01-2024|Completed|\n",
            "|ORD008  |C007       |Bangalore|Home       |Vacuum     |28000  |2024-01-09|Completed|\n",
            "|ORD009  |C002       |Mumbai   |Electronics|Laptop     |55000  |2024-01-10|Completed|\n",
            "|ORD010  |C008       |Delhi    |Home       |AirPurifier|38000  |2024-01-10|Completed|\n",
            "|ORD011  |C009       |Mumbai   |Home       |Vacuum     |29000  |2024-01-11|Completed|\n",
            "|ORD012  |C010       |Bangalore|Electronics|Mobile     |33000  |2024-01-11|Completed|\n",
            "|ORD013  |C003       |Bangalore|Home       |Mixer      |21000  |2024-01-12|Completed|\n",
            "|ORD014  |C004       |Delhi    |Electronics|Tablet     |26000  |2024-01-12|Completed|\n",
            "|ORD015  |C005       |Chennai  |Electronics|Laptop     |62000  |2024-01-13|Completed|\n",
            "|ORD016  |C006       |Mumbai   |Home       |AirPurifier|40000  |2024-01-13|Completed|\n",
            "|ORD017  |C007       |Bangalore|Electronics|Laptop     |51000  |2024-01-14|Completed|\n",
            "|ORD018  |C008       |Delhi    |Home       |Vacuum     |31000  |2024-01-14|Completed|\n",
            "|ORD019  |C009       |Mumbai   |Electronics|Tablet     |29000  |2024-01-15|Completed|\n",
            "|ORD020  |C010       |Bangalore|Electronics|Laptop     |54000  |2024-01-15|Completed|\n",
            "+--------+-----------+---------+-----------+-----------+-------+----------+---------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "from pyspark.sql.functions import col, regexp_replace, lower, initcap\n",
        "\n",
        "df_q5 = df_q4  # use the output from Q4\n",
        "\n",
        "for c in [\"city\", \"category\", \"product\"]:\n",
        "    col_norm = regexp_replace(col(c), r\"\\s+\", \" \")                       # collapse multiple spaces\n",
        "    col_norm = regexp_replace(col_norm, r\"(?<=[a-z])(?=[A-Z])\", \" \")     # split camelCase/PascalCase\n",
        "    col_norm = initcap(lower(col_norm))                                  # Title Case\n",
        "    df_q5 = df_q5.withColumn(c, col_norm)\n",
        "\n",
        "df_q5.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPt8TfvkkBAz",
        "outputId": "e17eb395-6943-482d-9e74-574d91f8b1b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+---------+-----------+------------+-------+----------+---------+\n",
            "|order_id|customer_id|city     |category   |product     |amount |order_date|status   |\n",
            "+--------+-----------+---------+-----------+------------+-------+----------+---------+\n",
            "|ORD001  |C001       |Delhi    |Electronics|Laptop      |45000  |2024-01-05|Completed|\n",
            "|ORD002  |C002       |Mumbai   |Electronics|Mobile      |32000  |05/01/2024|Completed|\n",
            "|ORD003  |C003       |Bangalore|Electronics|Tablet      |30000  |2024/01/06|Completed|\n",
            "|ORD004  |C004       |Delhi    |Electronics|Laptop      |       |2024-01-07|Cancelled|\n",
            "|ORD005  |C005       |Chennai  |Electronics|Mobile      |invalid|2024-01-08|Completed|\n",
            "|ORD006  |C006       |Mumbai   |Home       |Mixer       |NULL   |2024-01-08|Completed|\n",
            "|ORD007  |C001       |Delhi    |Electronics|Laptop      |47000  |09-01-2024|Completed|\n",
            "|ORD008  |C007       |Bangalore|Home       |Vacuum      |28000  |2024-01-09|Completed|\n",
            "|ORD009  |C002       |Mumbai   |Electronics|Laptop      |55000  |2024-01-10|Completed|\n",
            "|ORD010  |C008       |Delhi    |Home       |Air Purifier|38000  |2024-01-10|Completed|\n",
            "|ORD011  |C009       |Mumbai   |Home       |Vacuum      |29000  |2024-01-11|Completed|\n",
            "|ORD012  |C010       |Bangalore|Electronics|Mobile      |33000  |2024-01-11|Completed|\n",
            "|ORD013  |C003       |Bangalore|Home       |Mixer       |21000  |2024-01-12|Completed|\n",
            "|ORD014  |C004       |Delhi    |Electronics|Tablet      |26000  |2024-01-12|Completed|\n",
            "|ORD015  |C005       |Chennai  |Electronics|Laptop      |62000  |2024-01-13|Completed|\n",
            "|ORD016  |C006       |Mumbai   |Home       |Air Purifier|40000  |2024-01-13|Completed|\n",
            "|ORD017  |C007       |Bangalore|Electronics|Laptop      |51000  |2024-01-14|Completed|\n",
            "|ORD018  |C008       |Delhi    |Home       |Vacuum      |31000  |2024-01-14|Completed|\n",
            "|ORD019  |C009       |Mumbai   |Electronics|Tablet      |29000  |2024-01-15|Completed|\n",
            "|ORD020  |C010       |Bangalore|Electronics|Laptop      |54000  |2024-01-15|Completed|\n",
            "+--------+-----------+---------+-----------+------------+-------+----------+---------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task6\n",
        "\n",
        "from pyspark.sql.functions import regexp_replace, when\n",
        "\n",
        "df_q6 = df_q5\n",
        "\n",
        "# Extract only digits; anything else becomes empty -> invalid\n",
        "df_q6 = df_q6.withColumn(\"amount_digits\", regexp_replace(col(\"amount\"), r\"[^0-9]\", \"\"))\n",
        "\n",
        "# Cast to int if digits exist, else set to null\n",
        "df_q6 = df_q6.withColumn(\n",
        "    \"amount\",\n",
        "    when(col(\"amount_digits\").rlike(r\"^\\d+$\"), col(\"amount_digits\").cast(\"int\")).otherwise(None)\n",
        ").drop(\"amount_digits\")\n",
        "\n",
        "df_q6.select(\"order_id\", \"amount\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRCatIhQkPNv",
        "outputId": "efbe2b06-f319-406c-c6c0-d29d8ae1abf1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+\n",
            "|order_id|amount|\n",
            "+--------+------+\n",
            "|  ORD001| 45000|\n",
            "|  ORD002| 32000|\n",
            "|  ORD003| 30000|\n",
            "|  ORD004|  NULL|\n",
            "|  ORD005|  NULL|\n",
            "|  ORD006|  NULL|\n",
            "|  ORD007| 47000|\n",
            "|  ORD008| 28000|\n",
            "|  ORD009| 55000|\n",
            "|  ORD010| 38000|\n",
            "|  ORD011| 29000|\n",
            "|  ORD012| 33000|\n",
            "|  ORD013| 21000|\n",
            "|  ORD014| 26000|\n",
            "|  ORD015| 62000|\n",
            "|  ORD016| 40000|\n",
            "|  ORD017| 51000|\n",
            "|  ORD018| 31000|\n",
            "|  ORD019| 29000|\n",
            "|  ORD020| 54000|\n",
            "+--------+------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task7\n",
        "\n",
        "df_q7 = df_q6.filter(col(\"amount\").isNotNull())\n",
        "\n",
        "df_q7.select(\"order_id\", \"amount\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD5v0qSYkVar",
        "outputId": "4dc6b15b-2e7b-4126-a612-7f6729eb2517"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+\n",
            "|order_id|amount|\n",
            "+--------+------+\n",
            "|  ORD001| 45000|\n",
            "|  ORD002| 32000|\n",
            "|  ORD003| 30000|\n",
            "|  ORD007| 47000|\n",
            "|  ORD008| 28000|\n",
            "|  ORD009| 55000|\n",
            "|  ORD010| 38000|\n",
            "|  ORD011| 29000|\n",
            "|  ORD012| 33000|\n",
            "|  ORD013| 21000|\n",
            "|  ORD014| 26000|\n",
            "|  ORD015| 62000|\n",
            "|  ORD016| 40000|\n",
            "|  ORD017| 51000|\n",
            "|  ORD018| 31000|\n",
            "|  ORD019| 29000|\n",
            "|  ORD020| 54000|\n",
            "|  ORD020| 54000|\n",
            "+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 8\n",
        "from pyspark.sql.functions import col, to_date, when\n",
        "\n",
        "df_q8 = df_q7.withColumn(\n",
        "    \"order_date\",\n",
        "    when(col(\"order_date\").rlike(r\"^\\d{4}-\\d{2}-\\d{2}$\"), to_date(col(\"order_date\"), \"yyyy-MM-dd\"))\n",
        "    .when(col(\"order_date\").rlike(r\"^\\d{2}/\\d{2}/\\d{4}$\"), to_date(col(\"order_date\"), \"dd/MM/yyyy\"))\n",
        "    .when(col(\"order_date\").rlike(r\"^\\d{4}/\\d{2}/\\d{2}$\"), to_date(col(\"order_date\"), \"yyyy/MM/dd\"))\n",
        "    .when(col(\"order_date\").rlike(r\"^\\d{2}-\\d{2}-\\d{4}$\"), to_date(col(\"order_date\"), \"dd-MM-yyyy\"))\n",
        "    .otherwise(None)\n",
        ").filter(col(\"order_date\").isNotNull())\n",
        "\n",
        "df_q8.select(\"order_id\", \"order_date\").show(truncate=False)\n",
        "df_q8.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTW6EDJMkZnj",
        "outputId": "b6965fa1-0d88-49da-ad86-460bd56219e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+\n",
            "|order_id|order_date|\n",
            "+--------+----------+\n",
            "|ORD001  |2024-01-05|\n",
            "|ORD002  |2024-01-05|\n",
            "|ORD003  |2024-01-06|\n",
            "|ORD007  |2024-01-09|\n",
            "|ORD008  |2024-01-09|\n",
            "|ORD009  |2024-01-10|\n",
            "|ORD010  |2024-01-10|\n",
            "|ORD011  |2024-01-11|\n",
            "|ORD012  |2024-01-11|\n",
            "|ORD013  |2024-01-12|\n",
            "|ORD014  |2024-01-12|\n",
            "|ORD015  |2024-01-13|\n",
            "|ORD016  |2024-01-13|\n",
            "|ORD017  |2024-01-14|\n",
            "|ORD018  |2024-01-14|\n",
            "|ORD019  |2024-01-15|\n",
            "|ORD020  |2024-01-15|\n",
            "|ORD020  |2024-01-15|\n",
            "+--------+----------+\n",
            "\n",
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: integer (nullable = true)\n",
            " |-- order_date: date (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 9\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number, col\n",
        "\n",
        "# Sanity check: order_date must be DateType\n",
        "df_q8.printSchema()\n",
        "\n",
        "w = Window.partitionBy(\"order_id\").orderBy(\n",
        "    col(\"order_date\").desc(),\n",
        "    col(\"amount\").desc(),\n",
        "    col(\"customer_id\").desc()\n",
        ")\n",
        "\n",
        "df_q9 = df_q8.withColumn(\"rn\", row_number().over(w)) \\\n",
        "             .filter(col(\"rn\") == 1) \\\n",
        "             .drop(\"rn\")\n",
        "\n",
        "# Verify (should be 1 per order_id)\n",
        "df_q9.groupBy(\"order_id\").count().orderBy(col(\"order_id\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G19QEK_rkgKx",
        "outputId": "7524db26-12a2-41a3-add2-ede3865e5fa2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: integer (nullable = true)\n",
            " |-- order_date: date (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n",
            "+--------+-----+\n",
            "|order_id|count|\n",
            "+--------+-----+\n",
            "|  ORD001|    1|\n",
            "|  ORD002|    1|\n",
            "|  ORD003|    1|\n",
            "|  ORD007|    1|\n",
            "|  ORD008|    1|\n",
            "|  ORD009|    1|\n",
            "|  ORD010|    1|\n",
            "|  ORD011|    1|\n",
            "|  ORD012|    1|\n",
            "|  ORD013|    1|\n",
            "|  ORD014|    1|\n",
            "|  ORD015|    1|\n",
            "|  ORD016|    1|\n",
            "|  ORD017|    1|\n",
            "|  ORD018|    1|\n",
            "|  ORD019|    1|\n",
            "|  ORD020|    1|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 10\n",
        "from pyspark.sql.functions import lower, col\n",
        "\n",
        "# Assume df_q9 is your DataFrame after deduplication\n",
        "df_q10 = df_q9.withColumn(\"status_norm\", lower(col(\"status\"))) \\\n",
        "              .filter(col(\"status_norm\") == \"completed\") \\\n",
        "              .drop(\"status_norm\")\n",
        "\n",
        "# Verify\n",
        "df_q10.select(\"order_id\", \"status\").show(truncate=False)\n",
        "print(\"Final cleaned record count:\", df_q10.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4_jppObltq-",
        "outputId": "000bc76e-77e2-45e8-b8bf-feaa5209e64d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+\n",
            "|order_id|status   |\n",
            "+--------+---------+\n",
            "|ORD001  |Completed|\n",
            "|ORD002  |Completed|\n",
            "|ORD003  |Completed|\n",
            "|ORD007  |Completed|\n",
            "|ORD008  |Completed|\n",
            "|ORD009  |Completed|\n",
            "|ORD010  |Completed|\n",
            "|ORD011  |Completed|\n",
            "|ORD012  |Completed|\n",
            "|ORD013  |Completed|\n",
            "|ORD014  |Completed|\n",
            "|ORD015  |Completed|\n",
            "|ORD016  |Completed|\n",
            "|ORD017  |Completed|\n",
            "|ORD018  |Completed|\n",
            "|ORD019  |Completed|\n",
            "|ORD020  |Completed|\n",
            "+--------+---------+\n",
            "\n",
            "Final cleaned record count: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Task 11: Counts before vs after cleaning\n",
        "before_count = raw_df.count()\n",
        "after_count = df_q10.count()\n",
        "\n",
        "print(f\"Records BEFORE cleaning: {before_count}\")\n",
        "print(f\"Records AFTER cleaning:  {after_count}\")\n",
        "print(f\"Rows removed during cleaning: {before_count - after_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXxOWs76mE9H",
        "outputId": "846e5d1a-4481-4fbc-befc-46ac352cd3e5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Records BEFORE cleaning: 21\n",
            "Records AFTER cleaning:  17\n",
            "Rows removed during cleaning: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Task 12: Null checks in key columns\n",
        "null_checks = df_q10.selectExpr(\n",
        "    \"sum(case when order_id  IS NULL then 1 else 0 end) as null_order_id\",\n",
        "    \"sum(case when amount    IS NULL then 1 else 0 end) as null_amount\",\n",
        "    \"sum(case when order_date IS NULL then 1 else 0 end) as null_order_date\"\n",
        ").collect()[0]\n",
        "\n",
        "print(\"Nulls in key columns:\")\n",
        "print(f\"- order_id:   {null_checks['null_order_id']}\")\n",
        "print(f\"- amount:     {null_checks['null_amount']}\")\n",
        "print(f\"- order_date: {null_checks['null_order_date']}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK_JZ2oWmE7x",
        "outputId": "4ffdebf3-beaf-4be8-b477-a424be7e69a3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulls in key columns:\n",
            "- order_id:   0\n",
            "- amount:     0\n",
            "- order_date: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Task 13: Print schema and programmatic type checks\n",
        "df_q10.printSchema()\n",
        "\n",
        "# Programmatic checks\n",
        "schema_ok = (\n",
        "    dict(df_q10.dtypes) == {\n",
        "        'order_id': 'string',\n",
        "        'customer_id': 'string',\n",
        "        'city': 'string',\n",
        "        'category': 'string',\n",
        "        'product': 'string',\n",
        "        'amount': 'int',\n",
        "        'order_date': 'date',\n",
        "        'status': 'string'\n",
        "    }\n",
        ")\n",
        "print(\"Schema matches expected types:\", schema_ok)\n",
        "\n",
        "# More explicit assertions\n",
        "types = dict(df_q10.dtypes)\n",
        "assert types['order_id']   == 'string'\n",
        "assert types['customer_id'] == 'string'\n",
        "assert types['city']       == 'string'\n",
        "assert types['category']   == 'string'\n",
        "assert types['product']    == 'string'\n",
        "assert types['status']     == 'string'\n",
        "assert types['amount']     == 'int'\n",
        "assert types['order_date'] == 'date'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7KtaG4DmE5Q",
        "outputId": "86f3ff83-6ae0-45c5-c315-65a3233fb313"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: integer (nullable = true)\n",
            " |-- order_date: date (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n",
            "Schema matches expected types: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 14\n",
        "from pyspark.sql.functions import sum as F_sum, col\n",
        "\n",
        "revenue_by_city = df_q10.groupBy(\"city\").agg(F_sum(\"amount\").alias(\"total_revenue\")) \\\n",
        "                        .orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "revenue_by_city.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aox6KxZKmE1I",
        "outputId": "7fd9549c-dd49-4d94-c6bf-11cc4ebf2496"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|city     |total_revenue|\n",
            "+---------+-------------+\n",
            "|Bangalore|217000       |\n",
            "|Delhi    |187000       |\n",
            "|Mumbai   |185000       |\n",
            "|Chennai  |62000        |\n",
            "+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task15\n",
        "revenue_by_category = df_q10.groupBy(\"category\").agg(F_sum(\"amount\").alias(\"total_revenue\")) \\\n",
        "                            .orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "revenue_by_category.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95nx7AHxmEyu",
        "outputId": "5f38a5a4-5cbe-4a3d-f367-99433c7db55f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+\n",
            "|category   |total_revenue|\n",
            "+-----------+-------------+\n",
            "|Electronics|464000       |\n",
            "|Home       |187000       |\n",
            "+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task16\n",
        "revenue_by_product = df_q10.groupBy(\"product\").agg(F_sum(\"amount\").alias(\"total_revenue\")) \\\n",
        "                           .orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "revenue_by_product.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyX8aF2DmEv2",
        "outputId": "d2a68bac-fb75-4aee-8dd9-3f9ce2582078"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+\n",
            "|product     |total_revenue|\n",
            "+------------+-------------+\n",
            "|Laptop      |314000       |\n",
            "|Vacuum      |88000        |\n",
            "|Tablet      |85000        |\n",
            "|Air Purifier|78000        |\n",
            "|Mobile      |65000        |\n",
            "|Mixer       |21000        |\n",
            "+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task17\n",
        "from pyspark.sql.functions import avg as F_avg, count as F_count\n",
        "\n",
        "aov_by_city = df_q10.groupBy(\"city\") \\\n",
        "    .agg(\n",
        "        F_avg(\"amount\").alias(\"avg_order_value\"),\n",
        "        F_count(\"*\").alias(\"order_count\")\n",
        "    ) \\\n",
        "    .orderBy(col(\"avg_order_value\").desc())\n",
        "\n",
        "aov_by_city.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOnl3ol1mEsC",
        "outputId": "f2254d8a-2c5d-451b-85d8-a1a68771f83e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+-----------+\n",
            "|city     |avg_order_value   |order_count|\n",
            "+---------+------------------+-----------+\n",
            "|Chennai  |62000.0           |1          |\n",
            "|Delhi    |37400.0           |5          |\n",
            "|Mumbai   |37000.0           |5          |\n",
            "|Bangalore|36166.666666666664|6          |\n",
            "+---------+------------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task18\n",
        "\n",
        "top3_products = revenue_by_product.limit(3)\n",
        "top3_products.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q463NQMTmEmt",
        "outputId": "af47049a-9eb1-4925-c7cb-ce27f5b939c5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+\n",
            "|product|total_revenue|\n",
            "+-------+-------------+\n",
            "|Laptop |314000       |\n",
            "|Vacuum |88000        |\n",
            "|Tablet |85000        |\n",
            "+-------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task19\n",
        "from pyspark.sql.functions import sum as F_sum, col\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import dense_rank\n",
        "\n",
        "# Aggregate: total revenue per city\n",
        "city_revenue = df_q10.groupBy(\"city\").agg(F_sum(\"amount\").alias(\"total_revenue\"))\n",
        "\n",
        "# Window for ranking across all cities by total_revenue (descending)\n",
        "w_city = Window.orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "# Rank cities\n",
        "city_ranked = city_revenue.withColumn(\"rank\", dense_rank().over(w_city)) \\\n",
        "                          .orderBy(col(\"rank\"), col(\"total_revenue\").desc(), col(\"city\"))\n",
        "\n",
        "city_ranked.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxGv7BEsmEkX",
        "outputId": "cefbd70b-3f9a-46e3-c9ec-6ef89d66ea53"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+----+\n",
            "|city     |total_revenue|rank|\n",
            "+---------+-------------+----+\n",
            "|Bangalore|217000       |1   |\n",
            "|Delhi    |187000       |2   |\n",
            "|Mumbai   |185000       |3   |\n",
            "|Chennai  |62000        |4   |\n",
            "+---------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task20\n",
        "from pyspark.sql.functions import sum as F_sum, col\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import dense_rank\n",
        "\n",
        "# Aggregate: revenue per product within each category\n",
        "cat_prod_revenue = df_q10.groupBy(\"category\", \"product\") \\\n",
        "                         .agg(F_sum(\"amount\").alias(\"total_revenue\"))\n",
        "\n",
        "# Window partitioned by category; order by revenue desc\n",
        "w_cat_prod = Window.partitionBy(\"category\").orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "# Rank products within each category\n",
        "cat_prod_ranked = cat_prod_revenue.withColumn(\"rank_within_category\", dense_rank().over(w_cat_prod)) \\\n",
        "                                  .orderBy(col(\"category\"), col(\"rank_within_category\"), col(\"total_revenue\").desc())\n",
        "\n",
        "cat_prod_ranked.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945tZ1ADnlfh",
        "outputId": "ae47227b-bb6f-4e9a-c6e4-eecfac962dfd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+-------------+--------------------+\n",
            "|category   |product     |total_revenue|rank_within_category|\n",
            "+-----------+------------+-------------+--------------------+\n",
            "|Electronics|Laptop      |314000       |1                   |\n",
            "|Electronics|Tablet      |85000        |2                   |\n",
            "|Electronics|Mobile      |65000        |3                   |\n",
            "|Home       |Vacuum      |88000        |1                   |\n",
            "|Home       |Air Purifier|78000        |2                   |\n",
            "|Home       |Mixer       |21000        |3                   |\n",
            "+-----------+------------+-------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task21\n",
        "top_product_per_category = cat_prod_ranked.filter(col(\"rank_within_category\") == 1) \\\n",
        "                                          .orderBy(col(\"category\"))\n",
        "\n",
        "top_product_per_category.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL8eyrM-nlcB",
        "outputId": "9f101a9c-7e59-4cb6-9441-ec454aa1d089"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------------+--------------------+\n",
            "|category   |product|total_revenue|rank_within_category|\n",
            "+-----------+-------+-------------+--------------------+\n",
            "|Electronics|Laptop |314000       |1                   |\n",
            "|Home       |Vacuum |88000        |1                   |\n",
            "+-----------+-------+-------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Task 22: Cache the cleaned DataFrame\n",
        "df_cached = df_q10.cache()\n",
        "\n",
        "print(\"Caching df_q10 ...\")\n",
        "df_cached.count()\n",
        "\n",
        "from pyspark import StorageLevel\n",
        "print(\"Default storage level:\", StorageLevel.MEMORY_ONLY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLFX_oBnnlZX",
        "outputId": "b982bdbe-15d8-4bfc-a4bd-d1495dc093a9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching df_q10 ...\n",
            "Default storage level: Memory Serialized 1x Replicated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 23\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Total revenue by city\n",
        "revenue_by_city = df_cached.groupBy(\"city\").agg(F.sum(\"amount\").alias(\"total_revenue\")) \\\n",
        "                           .orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "# Total revenue by category\n",
        "revenue_by_category = df_cached.groupBy(\"category\").agg(F.sum(\"amount\").alias(\"total_revenue\")) \\\n",
        "                               .orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "# AOV by city, with count\n",
        "aov_by_city = df_cached.groupBy(\"city\") \\\n",
        "    .agg(F.avg(\"amount\").alias(\"avg_order_value\"), F.count(\"*\").alias(\"order_count\")) \\\n",
        "    .orderBy(col(\"avg_order_value\").desc())\n",
        "\n",
        "# Top products by revenue\n",
        "revenue_by_product = df_cached.groupBy(\"product\").agg(F.sum(\"amount\").alias(\"total_revenue\")) \\\n",
        "                              .orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "print(\"Revenue by city:\")\n",
        "revenue_by_city.show(truncate=False)\n",
        "\n",
        "print(\"Revenue by category:\")\n",
        "revenue_by_category.show(truncate=False)\n",
        "\n",
        "print(\"AOV by city:\")\n",
        "aov_by_city.show(truncate=False)\n",
        "\n",
        "print(\"Revenue by product (top 10):\")\n",
        "revenue_by_product.limit(10).show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ9rfofsnlW0",
        "outputId": "9e81d9d8-d854-41ee-83b8-f4c276b3df63"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Revenue by city:\n",
            "+---------+-------------+\n",
            "|city     |total_revenue|\n",
            "+---------+-------------+\n",
            "|Bangalore|217000       |\n",
            "|Delhi    |187000       |\n",
            "|Mumbai   |185000       |\n",
            "|Chennai  |62000        |\n",
            "+---------+-------------+\n",
            "\n",
            "Revenue by category:\n",
            "+-----------+-------------+\n",
            "|category   |total_revenue|\n",
            "+-----------+-------------+\n",
            "|Electronics|464000       |\n",
            "|Home       |187000       |\n",
            "+-----------+-------------+\n",
            "\n",
            "AOV by city:\n",
            "+---------+------------------+-----------+\n",
            "|city     |avg_order_value   |order_count|\n",
            "+---------+------------------+-----------+\n",
            "|Chennai  |62000.0           |1          |\n",
            "|Delhi    |37400.0           |5          |\n",
            "|Mumbai   |37000.0           |5          |\n",
            "|Bangalore|36166.666666666664|6          |\n",
            "+---------+------------------+-----------+\n",
            "\n",
            "Revenue by product (top 10):\n",
            "+------------+-------------+\n",
            "|product     |total_revenue|\n",
            "+------------+-------------+\n",
            "|Laptop      |314000       |\n",
            "|Vacuum      |88000        |\n",
            "|Tablet      |85000        |\n",
            "|Air Purifier|78000        |\n",
            "|Mobile      |65000        |\n",
            "|Mixer       |21000        |\n",
            "+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 24: Explain execution plans with details\n",
        "print(\"Explain plan — revenue_by_city:\")\n",
        "revenue_by_city.explain(True)\n",
        "\n",
        "print(\"Explain plan — revenue_by_category:\")\n",
        "revenue_by_category.explain(True)\n",
        "\n",
        "print(\"Explain plan — aov_by_city:\")\n",
        "aov_by_city.explain(True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVJ-g31bnlTz",
        "outputId": "c48a19e4-d5f1-4e94-d2ba-e0a3a6e5d99b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain plan — revenue_by_city:\n",
            "== Parsed Logical Plan ==\n",
            "'Sort ['total_revenue DESC NULLS LAST], true\n",
            "+- Aggregate [city#86], [city#86, sum(amount#115) AS total_revenue#785L]\n",
            "   +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "      +- Filter (status_norm#197 = completed)\n",
            "         +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, lower(status#60) AS status_norm#197]\n",
            "            +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "               +- Filter (rn#176 = 1)\n",
            "                  +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176]\n",
            "                     +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176, rn#176]\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                              +- Filter isnotnull(order_date#168)\n",
            "                                 +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN to_date(order_date#59, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN to_date(order_date#59, Some(dd/MM/yyyy), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN to_date(order_date#59, Some(yyyy/MM/dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN to_date(order_date#59, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date#168, status#60]\n",
            "                                    +- Filter isnotnull(amount#115)\n",
            "                                       +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#59, status#60]\n",
            "                                          +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) ELSE cast(null as int) END AS amount#115, order_date#59, status#60, amount_digits#114]\n",
            "                                             +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#58, order_date#59, status#60, regexp_replace(amount#58, [^0-9], , 1) AS amount_digits#114]\n",
            "                                                +- Project [order_id#53, customer_id#54, city#86, category#87, initcap(lower(regexp_replace(regexp_replace(product#57, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, amount#58, order_date#59, status#60]\n",
            "                                                   +- Project [order_id#53, customer_id#54, city#86, initcap(lower(regexp_replace(regexp_replace(category#56, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, product#57, amount#58, order_date#59, status#60]\n",
            "                                                      +- Project [order_id#53, customer_id#54, initcap(lower(regexp_replace(regexp_replace(city#55, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, category#56, product#57, amount#58, order_date#59, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, trim(city#2, None) AS city#55, trim(category#3, None) AS category#56, trim(product#4, None) AS product#57, trim(amount#5, None) AS amount#58, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60]\n",
            "                                                            +- LogicalRDD [order_id#0, customer_id#1, city#2, category#3, product#4, amount#5, order_date#6, status#7], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, total_revenue: bigint\n",
            "Sort [total_revenue#785L DESC NULLS LAST], true\n",
            "+- Aggregate [city#86], [city#86, sum(amount#115) AS total_revenue#785L]\n",
            "   +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "      +- Filter (status_norm#197 = completed)\n",
            "         +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, lower(status#60) AS status_norm#197]\n",
            "            +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "               +- Filter (rn#176 = 1)\n",
            "                  +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176]\n",
            "                     +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176, rn#176]\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                              +- Filter isnotnull(order_date#168)\n",
            "                                 +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN to_date(order_date#59, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN to_date(order_date#59, Some(dd/MM/yyyy), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN to_date(order_date#59, Some(yyyy/MM/dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN to_date(order_date#59, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date#168, status#60]\n",
            "                                    +- Filter isnotnull(amount#115)\n",
            "                                       +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#59, status#60]\n",
            "                                          +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) ELSE cast(null as int) END AS amount#115, order_date#59, status#60, amount_digits#114]\n",
            "                                             +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#58, order_date#59, status#60, regexp_replace(amount#58, [^0-9], , 1) AS amount_digits#114]\n",
            "                                                +- Project [order_id#53, customer_id#54, city#86, category#87, initcap(lower(regexp_replace(regexp_replace(product#57, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, amount#58, order_date#59, status#60]\n",
            "                                                   +- Project [order_id#53, customer_id#54, city#86, initcap(lower(regexp_replace(regexp_replace(category#56, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, product#57, amount#58, order_date#59, status#60]\n",
            "                                                      +- Project [order_id#53, customer_id#54, initcap(lower(regexp_replace(regexp_replace(city#55, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, category#56, product#57, amount#58, order_date#59, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, trim(city#2, None) AS city#55, trim(category#3, None) AS category#56, trim(product#4, None) AS product#57, trim(amount#5, None) AS amount#58, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60]\n",
            "                                                            +- LogicalRDD [order_id#0, customer_id#1, city#2, category#3, product#4, amount#5, order_date#6, status#7], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Sort [total_revenue#785L DESC NULLS LAST], true\n",
            "+- Aggregate [city#86], [city#86, sum(amount#115) AS total_revenue#785L]\n",
            "   +- Project [city#86, amount#115]\n",
            "      +- InMemoryRelation [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- AdaptiveSparkPlan isFinalPlan=true\n",
            "               +- == Final Plan ==\n",
            "                  ResultQueryStage 1\n",
            "                  +- *(3) Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                     +- *(3) Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                              +- *(2) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                 +- ShuffleQueryStage 0\n",
            "                                    +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3401]\n",
            "                                       +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                          +- *(1) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                             +- *(1) Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                +- *(1) Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                   +- *(1) Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                      +- *(1) Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "               +- == Initial Plan ==\n",
            "                  Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                  +- Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                     +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                        +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                           +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                              +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3358]\n",
            "                                 +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                    +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                       +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                          +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                             +- Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                +- Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [total_revenue#785L DESC NULLS LAST], true, 0\n",
            "   +- Exchange rangepartitioning(total_revenue#785L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=3779]\n",
            "      +- HashAggregate(keys=[city#86], functions=[sum(amount#115)], output=[city#86, total_revenue#785L])\n",
            "         +- Exchange hashpartitioning(city#86, 200), ENSURE_REQUIREMENTS, [plan_id=3776]\n",
            "            +- HashAggregate(keys=[city#86], functions=[partial_sum(amount#115)], output=[city#86, sum#950L])\n",
            "               +- InMemoryTableScan [city#86, amount#115]\n",
            "                     +- InMemoryRelation [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                           +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                              +- == Final Plan ==\n",
            "                                 ResultQueryStage 1\n",
            "                                 +- *(3) Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                    +- *(3) Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                                       +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                                          +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                                             +- *(2) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                +- ShuffleQueryStage 0\n",
            "                                                   +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3401]\n",
            "                                                      +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                                         +- *(1) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                            +- *(1) Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                               +- *(1) Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                                  +- *(1) Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                                     +- *(1) Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "                              +- == Initial Plan ==\n",
            "                                 Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                 +- Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                                    +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                                       +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                                          +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                             +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3358]\n",
            "                                                +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                                   +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                      +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                            +- Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                               +- Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "\n",
            "Explain plan — revenue_by_category:\n",
            "== Parsed Logical Plan ==\n",
            "'Sort ['total_revenue DESC NULLS LAST], true\n",
            "+- Aggregate [category#87], [category#87, sum(amount#115) AS total_revenue#795L]\n",
            "   +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "      +- Filter (status_norm#197 = completed)\n",
            "         +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, lower(status#60) AS status_norm#197]\n",
            "            +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "               +- Filter (rn#176 = 1)\n",
            "                  +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176]\n",
            "                     +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176, rn#176]\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                              +- Filter isnotnull(order_date#168)\n",
            "                                 +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN to_date(order_date#59, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN to_date(order_date#59, Some(dd/MM/yyyy), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN to_date(order_date#59, Some(yyyy/MM/dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN to_date(order_date#59, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date#168, status#60]\n",
            "                                    +- Filter isnotnull(amount#115)\n",
            "                                       +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#59, status#60]\n",
            "                                          +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) ELSE cast(null as int) END AS amount#115, order_date#59, status#60, amount_digits#114]\n",
            "                                             +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#58, order_date#59, status#60, regexp_replace(amount#58, [^0-9], , 1) AS amount_digits#114]\n",
            "                                                +- Project [order_id#53, customer_id#54, city#86, category#87, initcap(lower(regexp_replace(regexp_replace(product#57, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, amount#58, order_date#59, status#60]\n",
            "                                                   +- Project [order_id#53, customer_id#54, city#86, initcap(lower(regexp_replace(regexp_replace(category#56, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, product#57, amount#58, order_date#59, status#60]\n",
            "                                                      +- Project [order_id#53, customer_id#54, initcap(lower(regexp_replace(regexp_replace(city#55, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, category#56, product#57, amount#58, order_date#59, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, trim(city#2, None) AS city#55, trim(category#3, None) AS category#56, trim(product#4, None) AS product#57, trim(amount#5, None) AS amount#58, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60]\n",
            "                                                            +- LogicalRDD [order_id#0, customer_id#1, city#2, category#3, product#4, amount#5, order_date#6, status#7], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "category: string, total_revenue: bigint\n",
            "Sort [total_revenue#795L DESC NULLS LAST], true\n",
            "+- Aggregate [category#87], [category#87, sum(amount#115) AS total_revenue#795L]\n",
            "   +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "      +- Filter (status_norm#197 = completed)\n",
            "         +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, lower(status#60) AS status_norm#197]\n",
            "            +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "               +- Filter (rn#176 = 1)\n",
            "                  +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176]\n",
            "                     +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176, rn#176]\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                              +- Filter isnotnull(order_date#168)\n",
            "                                 +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN to_date(order_date#59, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN to_date(order_date#59, Some(dd/MM/yyyy), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN to_date(order_date#59, Some(yyyy/MM/dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN to_date(order_date#59, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date#168, status#60]\n",
            "                                    +- Filter isnotnull(amount#115)\n",
            "                                       +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#59, status#60]\n",
            "                                          +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) ELSE cast(null as int) END AS amount#115, order_date#59, status#60, amount_digits#114]\n",
            "                                             +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#58, order_date#59, status#60, regexp_replace(amount#58, [^0-9], , 1) AS amount_digits#114]\n",
            "                                                +- Project [order_id#53, customer_id#54, city#86, category#87, initcap(lower(regexp_replace(regexp_replace(product#57, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, amount#58, order_date#59, status#60]\n",
            "                                                   +- Project [order_id#53, customer_id#54, city#86, initcap(lower(regexp_replace(regexp_replace(category#56, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, product#57, amount#58, order_date#59, status#60]\n",
            "                                                      +- Project [order_id#53, customer_id#54, initcap(lower(regexp_replace(regexp_replace(city#55, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, category#56, product#57, amount#58, order_date#59, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, trim(city#2, None) AS city#55, trim(category#3, None) AS category#56, trim(product#4, None) AS product#57, trim(amount#5, None) AS amount#58, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60]\n",
            "                                                            +- LogicalRDD [order_id#0, customer_id#1, city#2, category#3, product#4, amount#5, order_date#6, status#7], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Sort [total_revenue#795L DESC NULLS LAST], true\n",
            "+- Aggregate [category#87], [category#87, sum(amount#115) AS total_revenue#795L]\n",
            "   +- Project [category#87, amount#115]\n",
            "      +- InMemoryRelation [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- AdaptiveSparkPlan isFinalPlan=true\n",
            "               +- == Final Plan ==\n",
            "                  ResultQueryStage 1\n",
            "                  +- *(3) Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                     +- *(3) Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                              +- *(2) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                 +- ShuffleQueryStage 0\n",
            "                                    +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3401]\n",
            "                                       +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                          +- *(1) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                             +- *(1) Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                +- *(1) Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                   +- *(1) Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                      +- *(1) Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "               +- == Initial Plan ==\n",
            "                  Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                  +- Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                     +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                        +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                           +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                              +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3358]\n",
            "                                 +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                    +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                       +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                          +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                             +- Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                +- Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [total_revenue#795L DESC NULLS LAST], true, 0\n",
            "   +- Exchange rangepartitioning(total_revenue#795L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=3799]\n",
            "      +- HashAggregate(keys=[category#87], functions=[sum(amount#115)], output=[category#87, total_revenue#795L])\n",
            "         +- Exchange hashpartitioning(category#87, 200), ENSURE_REQUIREMENTS, [plan_id=3796]\n",
            "            +- HashAggregate(keys=[category#87], functions=[partial_sum(amount#115)], output=[category#87, sum#1162L])\n",
            "               +- InMemoryTableScan [category#87, amount#115]\n",
            "                     +- InMemoryRelation [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                           +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                              +- == Final Plan ==\n",
            "                                 ResultQueryStage 1\n",
            "                                 +- *(3) Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                    +- *(3) Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                                       +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                                          +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                                             +- *(2) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                +- ShuffleQueryStage 0\n",
            "                                                   +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3401]\n",
            "                                                      +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                                         +- *(1) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                            +- *(1) Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                               +- *(1) Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                                  +- *(1) Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                                     +- *(1) Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "                              +- == Initial Plan ==\n",
            "                                 Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                 +- Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                                    +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                                       +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                                          +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                             +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3358]\n",
            "                                                +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                                   +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                      +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                            +- Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                               +- Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "\n",
            "Explain plan — aov_by_city:\n",
            "== Parsed Logical Plan ==\n",
            "'Sort ['avg_order_value DESC NULLS LAST], true\n",
            "+- Aggregate [city#86], [city#86, avg(amount#115) AS avg_order_value#805, count(1) AS order_count#806L]\n",
            "   +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "      +- Filter (status_norm#197 = completed)\n",
            "         +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, lower(status#60) AS status_norm#197]\n",
            "            +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "               +- Filter (rn#176 = 1)\n",
            "                  +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176]\n",
            "                     +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176, rn#176]\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                              +- Filter isnotnull(order_date#168)\n",
            "                                 +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN to_date(order_date#59, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN to_date(order_date#59, Some(dd/MM/yyyy), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN to_date(order_date#59, Some(yyyy/MM/dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN to_date(order_date#59, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date#168, status#60]\n",
            "                                    +- Filter isnotnull(amount#115)\n",
            "                                       +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#59, status#60]\n",
            "                                          +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) ELSE cast(null as int) END AS amount#115, order_date#59, status#60, amount_digits#114]\n",
            "                                             +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#58, order_date#59, status#60, regexp_replace(amount#58, [^0-9], , 1) AS amount_digits#114]\n",
            "                                                +- Project [order_id#53, customer_id#54, city#86, category#87, initcap(lower(regexp_replace(regexp_replace(product#57, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, amount#58, order_date#59, status#60]\n",
            "                                                   +- Project [order_id#53, customer_id#54, city#86, initcap(lower(regexp_replace(regexp_replace(category#56, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, product#57, amount#58, order_date#59, status#60]\n",
            "                                                      +- Project [order_id#53, customer_id#54, initcap(lower(regexp_replace(regexp_replace(city#55, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, category#56, product#57, amount#58, order_date#59, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, trim(city#2, None) AS city#55, trim(category#3, None) AS category#56, trim(product#4, None) AS product#57, trim(amount#5, None) AS amount#58, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60]\n",
            "                                                            +- LogicalRDD [order_id#0, customer_id#1, city#2, category#3, product#4, amount#5, order_date#6, status#7], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, avg_order_value: double, order_count: bigint\n",
            "Sort [avg_order_value#805 DESC NULLS LAST], true\n",
            "+- Aggregate [city#86], [city#86, avg(amount#115) AS avg_order_value#805, count(1) AS order_count#806L]\n",
            "   +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "      +- Filter (status_norm#197 = completed)\n",
            "         +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, lower(status#60) AS status_norm#197]\n",
            "            +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "               +- Filter (rn#176 = 1)\n",
            "                  +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176]\n",
            "                     +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176, rn#176]\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                              +- Filter isnotnull(order_date#168)\n",
            "                                 +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN to_date(order_date#59, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN to_date(order_date#59, Some(dd/MM/yyyy), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN to_date(order_date#59, Some(yyyy/MM/dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN to_date(order_date#59, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date#168, status#60]\n",
            "                                    +- Filter isnotnull(amount#115)\n",
            "                                       +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#59, status#60]\n",
            "                                          +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) ELSE cast(null as int) END AS amount#115, order_date#59, status#60, amount_digits#114]\n",
            "                                             +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#58, order_date#59, status#60, regexp_replace(amount#58, [^0-9], , 1) AS amount_digits#114]\n",
            "                                                +- Project [order_id#53, customer_id#54, city#86, category#87, initcap(lower(regexp_replace(regexp_replace(product#57, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, amount#58, order_date#59, status#60]\n",
            "                                                   +- Project [order_id#53, customer_id#54, city#86, initcap(lower(regexp_replace(regexp_replace(category#56, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, product#57, amount#58, order_date#59, status#60]\n",
            "                                                      +- Project [order_id#53, customer_id#54, initcap(lower(regexp_replace(regexp_replace(city#55, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, category#56, product#57, amount#58, order_date#59, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, trim(city#2, None) AS city#55, trim(category#3, None) AS category#56, trim(product#4, None) AS product#57, trim(amount#5, None) AS amount#58, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60]\n",
            "                                                            +- LogicalRDD [order_id#0, customer_id#1, city#2, category#3, product#4, amount#5, order_date#6, status#7], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Sort [avg_order_value#805 DESC NULLS LAST], true\n",
            "+- Aggregate [city#86], [city#86, avg(amount#115) AS avg_order_value#805, count(1) AS order_count#806L]\n",
            "   +- Project [city#86, amount#115]\n",
            "      +- InMemoryRelation [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- AdaptiveSparkPlan isFinalPlan=true\n",
            "               +- == Final Plan ==\n",
            "                  ResultQueryStage 1\n",
            "                  +- *(3) Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                     +- *(3) Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                              +- *(2) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                 +- ShuffleQueryStage 0\n",
            "                                    +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3401]\n",
            "                                       +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                          +- *(1) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                             +- *(1) Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                +- *(1) Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                   +- *(1) Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                      +- *(1) Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "               +- == Initial Plan ==\n",
            "                  Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                  +- Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                     +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                        +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                           +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                              +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3358]\n",
            "                                 +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                    +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                       +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                          +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                             +- Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                +- Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [avg_order_value#805 DESC NULLS LAST], true, 0\n",
            "   +- Exchange rangepartitioning(avg_order_value#805 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=3819]\n",
            "      +- HashAggregate(keys=[city#86], functions=[avg(amount#115), count(1)], output=[city#86, avg_order_value#805, order_count#806L])\n",
            "         +- Exchange hashpartitioning(city#86, 200), ENSURE_REQUIREMENTS, [plan_id=3816]\n",
            "            +- HashAggregate(keys=[city#86], functions=[partial_avg(amount#115), partial_count(1)], output=[city#86, sum#1377, count#1378L, count#1379L])\n",
            "               +- InMemoryTableScan [city#86, amount#115]\n",
            "                     +- InMemoryRelation [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                           +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                              +- == Final Plan ==\n",
            "                                 ResultQueryStage 1\n",
            "                                 +- *(3) Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                    +- *(3) Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                                       +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                                          +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                                             +- *(2) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                +- ShuffleQueryStage 0\n",
            "                                                   +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3401]\n",
            "                                                      +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                                         +- *(1) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                            +- *(1) Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                               +- *(1) Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                                  +- *(1) Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                                     +- *(1) Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "                              +- == Initial Plan ==\n",
            "                                 Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                 +- Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                                    +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                                       +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                                          +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                             +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3358]\n",
            "                                                +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                                   +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                      +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                            +- Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                               +- Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Task 25: Repartition by 'city' (wide transformation with shuffle)\n",
        "df_city_part = df_cached.repartition(col(\"city\"))\n",
        "\n",
        "num_parts = df_city_part.rdd.getNumPartitions()\n",
        "print(\"Number of partitions after repartition by city:\", num_parts)\n",
        "\n",
        "revenue_by_city_part = df_city_part.groupBy(\"city\").agg(F.sum(\"amount\").alias(\"total_revenue\")) \\\n",
        "                                   .orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "revenue_by_city_part.explain(True)\n",
        "revenue_by_city_part.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSzQGTLGnlRP",
        "outputId": "c39b00a4-426e-47bc-dc10-f932ee0a0d35"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of partitions after repartition by city: 1\n",
            "== Parsed Logical Plan ==\n",
            "'Sort ['total_revenue DESC NULLS LAST], true\n",
            "+- Aggregate [city#86], [city#86, sum(amount#115) AS total_revenue#2245L]\n",
            "   +- RepartitionByExpression [city#86]\n",
            "      +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "         +- Filter (status_norm#197 = completed)\n",
            "            +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, lower(status#60) AS status_norm#197]\n",
            "               +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                  +- Filter (rn#176 = 1)\n",
            "                     +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176]\n",
            "                        +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176, rn#176]\n",
            "                           +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                              +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                 +- Filter isnotnull(order_date#168)\n",
            "                                    +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN to_date(order_date#59, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN to_date(order_date#59, Some(dd/MM/yyyy), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN to_date(order_date#59, Some(yyyy/MM/dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN to_date(order_date#59, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date#168, status#60]\n",
            "                                       +- Filter isnotnull(amount#115)\n",
            "                                          +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#59, status#60]\n",
            "                                             +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) ELSE cast(null as int) END AS amount#115, order_date#59, status#60, amount_digits#114]\n",
            "                                                +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#58, order_date#59, status#60, regexp_replace(amount#58, [^0-9], , 1) AS amount_digits#114]\n",
            "                                                   +- Project [order_id#53, customer_id#54, city#86, category#87, initcap(lower(regexp_replace(regexp_replace(product#57, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, amount#58, order_date#59, status#60]\n",
            "                                                      +- Project [order_id#53, customer_id#54, city#86, initcap(lower(regexp_replace(regexp_replace(category#56, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, product#57, amount#58, order_date#59, status#60]\n",
            "                                                         +- Project [order_id#53, customer_id#54, initcap(lower(regexp_replace(regexp_replace(city#55, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, category#56, product#57, amount#58, order_date#59, status#60]\n",
            "                                                            +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, trim(city#2, None) AS city#55, trim(category#3, None) AS category#56, trim(product#4, None) AS product#57, trim(amount#5, None) AS amount#58, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60]\n",
            "                                                               +- LogicalRDD [order_id#0, customer_id#1, city#2, category#3, product#4, amount#5, order_date#6, status#7], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, total_revenue: bigint\n",
            "Sort [total_revenue#2245L DESC NULLS LAST], true\n",
            "+- Aggregate [city#86], [city#86, sum(amount#115) AS total_revenue#2245L]\n",
            "   +- RepartitionByExpression [city#86]\n",
            "      +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "         +- Filter (status_norm#197 = completed)\n",
            "            +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, lower(status#60) AS status_norm#197]\n",
            "               +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                  +- Filter (rn#176 = 1)\n",
            "                     +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176]\n",
            "                        +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60, rn#176, rn#176]\n",
            "                           +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                              +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                 +- Filter isnotnull(order_date#168)\n",
            "                                    +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN to_date(order_date#59, Some(yyyy-MM-dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN to_date(order_date#59, Some(dd/MM/yyyy), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN to_date(order_date#59, Some(yyyy/MM/dd), Some(Etc/UTC), true) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN to_date(order_date#59, Some(dd-MM-yyyy), Some(Etc/UTC), true) ELSE cast(null as date) END AS order_date#168, status#60]\n",
            "                                       +- Filter isnotnull(amount#115)\n",
            "                                          +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#59, status#60]\n",
            "                                             +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) ELSE cast(null as int) END AS amount#115, order_date#59, status#60, amount_digits#114]\n",
            "                                                +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#58, order_date#59, status#60, regexp_replace(amount#58, [^0-9], , 1) AS amount_digits#114]\n",
            "                                                   +- Project [order_id#53, customer_id#54, city#86, category#87, initcap(lower(regexp_replace(regexp_replace(product#57, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, amount#58, order_date#59, status#60]\n",
            "                                                      +- Project [order_id#53, customer_id#54, city#86, initcap(lower(regexp_replace(regexp_replace(category#56, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, product#57, amount#58, order_date#59, status#60]\n",
            "                                                         +- Project [order_id#53, customer_id#54, initcap(lower(regexp_replace(regexp_replace(city#55, \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, category#56, product#57, amount#58, order_date#59, status#60]\n",
            "                                                            +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, trim(city#2, None) AS city#55, trim(category#3, None) AS category#56, trim(product#4, None) AS product#57, trim(amount#5, None) AS amount#58, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60]\n",
            "                                                               +- LogicalRDD [order_id#0, customer_id#1, city#2, category#3, product#4, amount#5, order_date#6, status#7], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Sort [total_revenue#2245L DESC NULLS LAST], true\n",
            "+- Aggregate [city#86], [city#86, sum(amount#115) AS total_revenue#2245L]\n",
            "   +- RepartitionByExpression [city#86]\n",
            "      +- Project [city#86, amount#115]\n",
            "         +- InMemoryRelation [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "               +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                  +- == Final Plan ==\n",
            "                     ResultQueryStage 1\n",
            "                     +- *(3) Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                        +- *(3) Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                           +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                              +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                                 +- *(2) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                    +- ShuffleQueryStage 0\n",
            "                                       +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3401]\n",
            "                                          +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                             +- *(1) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                +- *(1) Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                   +- *(1) Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                      +- *(1) Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                         +- *(1) Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "                  +- == Initial Plan ==\n",
            "                     Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                     +- Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                        +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                           +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                              +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                 +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3358]\n",
            "                                    +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                       +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                          +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                             +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                +- Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                   +- Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [total_revenue#2245L DESC NULLS LAST], true, 0\n",
            "   +- Exchange rangepartitioning(total_revenue#2245L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=3863]\n",
            "      +- HashAggregate(keys=[city#86], functions=[sum(amount#115)], output=[city#86, total_revenue#2245L])\n",
            "         +- HashAggregate(keys=[city#86], functions=[partial_sum(amount#115)], output=[city#86, sum#2376L])\n",
            "            +- Exchange hashpartitioning(city#86, 200), REPARTITION_BY_COL, [plan_id=3858]\n",
            "               +- InMemoryTableScan [city#86, amount#115]\n",
            "                     +- InMemoryRelation [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                           +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                              +- == Final Plan ==\n",
            "                                 ResultQueryStage 1\n",
            "                                 +- *(3) Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                    +- *(3) Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                                       +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                                          +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                                             +- *(2) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                +- ShuffleQueryStage 0\n",
            "                                                   +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3401]\n",
            "                                                      +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                                         +- *(1) Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                            +- *(1) Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                               +- *(1) Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                                  +- *(1) Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                                     +- *(1) Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "                              +- == Initial Plan ==\n",
            "                                 Project [order_id#53, customer_id#54, city#86, category#87, product#88, amount#115, order_date#168, status#60]\n",
            "                                 +- Filter (isnotnull(status#60) AND ((rn#176 = 1) AND (lower(status#60) = completed)))\n",
            "                                    +- Window [row_number() windowspecdefinition(order_id#53, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#176], [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST]\n",
            "                                       +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Final\n",
            "                                          +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                             +- Exchange hashpartitioning(order_id#53, 200), ENSURE_REQUIREMENTS, [plan_id=3358]\n",
            "                                                +- WindowGroupLimit [order_id#53], [order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], row_number(), 1, Partial\n",
            "                                                   +- Sort [order_id#53 ASC NULLS FIRST, order_date#168 DESC NULLS LAST, amount#115 DESC NULLS LAST, customer_id#54 DESC NULLS LAST], false, 0\n",
            "                                                      +- Project [order_id#53, customer_id#54, city#86, category#87, product#88, CASE WHEN RLIKE(amount_digits#114, ^\\d+$) THEN cast(amount_digits#114 as int) END AS amount#115, CASE WHEN RLIKE(order_date#59, ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(order_date#59, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(order_date#59, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(order_date#59, ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(order_date#59, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END AS order_date#168, status#60]\n",
            "                                                         +- Project [trim(order_id#0, None) AS order_id#53, trim(customer_id#1, None) AS customer_id#54, initcap(lower(regexp_replace(regexp_replace(trim(city#2, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS city#86, initcap(lower(regexp_replace(regexp_replace(trim(category#3, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS category#87, initcap(lower(regexp_replace(regexp_replace(trim(product#4, None), \\s+,  , 1), (?<=[a-z])(?=[A-Z]),  , 1))) AS product#88, trim(order_date#6, None) AS order_date#59, trim(status#7, None) AS status#60, regexp_replace(trim(amount#5, None), [^0-9], , 1) AS amount_digits#114]\n",
            "                                                            +- Filter (CASE WHEN RLIKE(regexp_replace(trim(amount#5, None), [^0-9], , 1), ^\\d+$) THEN isnotnull(cast(regexp_replace(trim(amount#5, None), [^0-9], , 1) as int)) ELSE false END AND isnotnull(CASE WHEN RLIKE(trim(order_date#6, None), ^\\d{4}-\\d{2}-\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}/\\d{2}/\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{4}/\\d{2}/\\d{2}$) THEN cast(gettimestamp(trim(order_date#6, None), yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) WHEN RLIKE(trim(order_date#6, None), ^\\d{2}-\\d{2}-\\d{4}$) THEN cast(gettimestamp(trim(order_date#6, None), dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), true) as date) END))\n",
            "                                                               +- Scan ExistingRDD[order_id#0,customer_id#1,city#2,category#3,product#4,amount#5,order_date#6,status#7]\n",
            "\n",
            "+---------+-------------+\n",
            "|city     |total_revenue|\n",
            "+---------+-------------+\n",
            "|Bangalore|217000       |\n",
            "|Delhi    |187000       |\n",
            "|Mumbai   |185000       |\n",
            "|Chennai  |62000        |\n",
            "+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set ONE of these based on your environment\n",
        "\n",
        "# Local / standard Spark\n",
        "base_path = \"/tmp/marketplace_out\"\n",
        "\n",
        "# If using Databricks/DBFS, uncomment this:\n",
        "# base_path = \"dbfs:/FileStore/marketplace_out\"\n",
        "\n",
        "orders_parquet_path = f\"{base_path}/orders_parquet\"\n",
        "analytics_orc_base  = f\"{base_path}/analytics_orc\"\n"
      ],
      "metadata": {
        "id": "y_lHCrIxpXnS"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#task 26\n",
        "from pyspark.sql.functions import year, month, col\n",
        "\n",
        "# Derive partitions for BI-friendly layout\n",
        "orders_for_write = df_q10 \\\n",
        "    .withColumn(\"order_year\",  year(col(\"order_date\"))) \\\n",
        "    .withColumn(\"order_month\", month(col(\"order_date\")))\n",
        "\n",
        "# Optional (good default in Spark 3.x; set explicitly if you want):\n",
        "spark.conf.set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
        "\n",
        "# Write Parquet partitioned by year, month, and city\n",
        "orders_for_write.write \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .partitionBy(\"order_year\", \"order_month\", \"city\") \\\n",
        "    .parquet(orders_parquet_path)\n",
        "\n",
        "print(f\" Order-level Parquet written to: {orders_parquet_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N88bqPBpIVO",
        "outputId": "75487256-addc-4e62-de29-96a767dc1263"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Order-level Parquet written to: /tmp/marketplace_out/orders_parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task27\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import dense_rank\n",
        "\n",
        "# Core aggregates\n",
        "revenue_by_city = df_q10.groupBy(\"city\").agg(F.sum(\"amount\").alias(\"total_revenue\"))\n",
        "revenue_by_category = df_q10.groupBy(\"category\").agg(F.sum(\"amount\").alias(\"total_revenue\"))\n",
        "revenue_by_product = df_q10.groupBy(\"product\").agg(F.sum(\"amount\").alias(\"total_revenue\"))\n",
        "aov_by_city = df_q10.groupBy(\"city\").agg(\n",
        "    F.avg(\"amount\").alias(\"avg_order_value\"),\n",
        "    F.count(\"*\").alias(\"order_count\")\n",
        ")\n",
        "\n",
        "# Top-3 products by revenue (dense_rank to include ties)\n",
        "w_prod = Window.orderBy(col(\"total_revenue\").desc())\n",
        "top_products_ranked = revenue_by_product.withColumn(\"rank\", dense_rank().over(w_prod)) \\\n",
        "                                        .filter(col(\"rank\") <= 3)\n",
        "\n",
        "# Optional: set ORC compression codec\n",
        "spark.conf.set(\"spark.sql.orc.compression.codec\", \"snappy\")\n",
        "\n",
        "# Paths\n",
        "orc_city_path     = f\"{analytics_orc_base}/revenue_by_city\"\n",
        "orc_cat_path      = f\"{analytics_orc_base}/revenue_by_category\"\n",
        "orc_prod_path     = f\"{analytics_orc_base}/revenue_by_product\"\n",
        "orc_aov_city_path = f\"{analytics_orc_base}/aov_by_city\"\n",
        "orc_top3_path     = f\"{analytics_orc_base}/top3_products_by_revenue\"\n",
        "\n",
        "# (Optional) reduce number of small files for demo purposes\n",
        "revenue_by_city.coalesce(1).write.mode(\"overwrite\").format(\"orc\").save(orc_city_path)\n",
        "revenue_by_category.coalesce(1).write.mode(\"overwrite\").format(\"orc\").save(orc_cat_path)\n",
        "revenue_by_product.coalesce(1).write.mode(\"overwrite\").format(\"orc\").save(orc_prod_path)\n",
        "aov_by_city.coalesce(1).write.mode(\"overwrite\").format(\"orc\").save(orc_aov_city_path)\n",
        "top_products_ranked.coalesce(1).write.mode(\"overwrite\").format(\"orc\").save(orc_top3_path)\n",
        "\n",
        "print(\"✅ Analytics ORC datasets written to:\")\n",
        "print(orc_city_path)\n",
        "print(orc_cat_path)\n",
        "print(orc_prod_path)\n",
        "print(orc_aov_city_path)\n",
        "print(orc_top3_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArOO4H1YpgMl",
        "outputId": "d83f7139-612e-4ce9-9298-90272256e827"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Analytics ORC datasets written to:\n",
            "/tmp/marketplace_out/analytics_orc/revenue_by_city\n",
            "/tmp/marketplace_out/analytics_orc/revenue_by_category\n",
            "/tmp/marketplace_out/analytics_orc/revenue_by_product\n",
            "/tmp/marketplace_out/analytics_orc/aov_by_city\n",
            "/tmp/marketplace_out/analytics_orc/top3_products_by_revenue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 28\n",
        "\n",
        "# --- Read back Parquet (order-level) ---\n",
        "orders_read = spark.read.parquet(orders_parquet_path)\n",
        "print(\" Orders Parquet schema:\")\n",
        "orders_read.printSchema()\n",
        "print(\"Sample rows from orders:\")\n",
        "orders_read.orderBy(\"order_date\", \"city\").show(truncate=False)\n",
        "\n",
        "# Schema assertions (adjust if you changed partitioning columns)\n",
        "expected_order_cols = {\n",
        "    'order_id': 'string',\n",
        "    'customer_id': 'string',\n",
        "    'city': 'string',          # present in data & also a partition column\n",
        "    'category': 'string',\n",
        "    'product': 'string',\n",
        "    'amount': 'int',\n",
        "    'order_date': 'date',\n",
        "    'status': 'string',\n",
        "    'order_year': 'int',\n",
        "    'order_month': 'int'\n",
        "}\n",
        "read_types = dict(orders_read.dtypes)\n",
        "missing = [c for c in expected_order_cols if c not in read_types]\n",
        "mismatched = {c:(read_types.get(c), t) for c,t in expected_order_cols.items() if read_types.get(c) != t}\n",
        "print(\"Validation — missing columns:\", missing)\n",
        "print(\"Validation — mismatched types (read vs expected):\", mismatched)\n",
        "\n",
        "# --- Read back ORC analytics ---\n",
        "rev_city_read = spark.read.format(\"orc\").load(orc_city_path)\n",
        "rev_cat_read  = spark.read.format(\"orc\").load(orc_cat_path)\n",
        "rev_prod_read = spark.read.format(\"orc\").load(orc_prod_path)\n",
        "aov_city_read = spark.read.format(\"orc\").load(orc_aov_city_path)\n",
        "top3_read     = spark.read.format(\"orc\").load(orc_top3_path)\n",
        "\n",
        "print(\"\\n ORC schemas:\")\n",
        "print(\"revenue_by_city:\")\n",
        "rev_city_read.printSchema()\n",
        "print(\"revenue_by_category:\")\n",
        "rev_cat_read.printSchema()\n",
        "print(\"revenue_by_product:\")\n",
        "rev_prod_read.printSchema()\n",
        "print(\"aov_by_city:\")\n",
        "aov_city_read.printSchema()\n",
        "print(\"top3_products_by_revenue:\")\n",
        "top3_read.printSchema()\n",
        "\n",
        "# Quick integrity checks\n",
        "print(\"\\nRow counts:\")\n",
        "print(\"revenue_by_city:\", rev_city_read.count())\n",
        "print(\"revenue_by_category:\", rev_cat_read.count())\n",
        "print(\"revenue_by_product:\", rev_prod_read.count())\n",
        "print(\"aov_by_city:\", aov_city_read.count())\n",
        "print(\"top3_products_by_revenue:\", top3_read.count())\n",
        "\n",
        "# Peek data\n",
        "rev_city_read.orderBy(F.col(\"total_revenue\").desc()).show(truncate=False)\n",
        "rev_cat_read.orderBy(F.col(\"total_revenue\").desc()).show(truncate=False)\n",
        "rev_prod_read.orderBy(F.col(\"total_revenue\").desc()).show(truncate=False)\n",
        "aov_city_read.orderBy(F.col(\"avg_order_value\").desc()).show(truncate=False)\n",
        "top3_read.orderBy(F.col(\"rank\"), F.col(\"total_revenue\").desc()).show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqlrwaJApuK_",
        "outputId": "b5841291-e253-4e7b-cb41-f5044cf21c02"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Orders Parquet schema:\n",
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- customer_id: string (nullable = true)\n",
            " |-- category: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: integer (nullable = true)\n",
            " |-- order_date: date (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            " |-- order_year: integer (nullable = true)\n",
            " |-- order_month: integer (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            "\n",
            "Sample rows from orders:\n",
            "+--------+-----------+-----------+------------+------+----------+---------+----------+-----------+---------+\n",
            "|order_id|customer_id|category   |product     |amount|order_date|status   |order_year|order_month|city     |\n",
            "+--------+-----------+-----------+------------+------+----------+---------+----------+-----------+---------+\n",
            "|ORD001  |C001       |Electronics|Laptop      |45000 |2024-01-05|Completed|2024      |1          |Delhi    |\n",
            "|ORD002  |C002       |Electronics|Mobile      |32000 |2024-01-05|Completed|2024      |1          |Mumbai   |\n",
            "|ORD003  |C003       |Electronics|Tablet      |30000 |2024-01-06|Completed|2024      |1          |Bangalore|\n",
            "|ORD008  |C007       |Home       |Vacuum      |28000 |2024-01-09|Completed|2024      |1          |Bangalore|\n",
            "|ORD007  |C001       |Electronics|Laptop      |47000 |2024-01-09|Completed|2024      |1          |Delhi    |\n",
            "|ORD010  |C008       |Home       |Air Purifier|38000 |2024-01-10|Completed|2024      |1          |Delhi    |\n",
            "|ORD009  |C002       |Electronics|Laptop      |55000 |2024-01-10|Completed|2024      |1          |Mumbai   |\n",
            "|ORD012  |C010       |Electronics|Mobile      |33000 |2024-01-11|Completed|2024      |1          |Bangalore|\n",
            "|ORD011  |C009       |Home       |Vacuum      |29000 |2024-01-11|Completed|2024      |1          |Mumbai   |\n",
            "|ORD013  |C003       |Home       |Mixer       |21000 |2024-01-12|Completed|2024      |1          |Bangalore|\n",
            "|ORD014  |C004       |Electronics|Tablet      |26000 |2024-01-12|Completed|2024      |1          |Delhi    |\n",
            "|ORD015  |C005       |Electronics|Laptop      |62000 |2024-01-13|Completed|2024      |1          |Chennai  |\n",
            "|ORD016  |C006       |Home       |Air Purifier|40000 |2024-01-13|Completed|2024      |1          |Mumbai   |\n",
            "|ORD017  |C007       |Electronics|Laptop      |51000 |2024-01-14|Completed|2024      |1          |Bangalore|\n",
            "|ORD018  |C008       |Home       |Vacuum      |31000 |2024-01-14|Completed|2024      |1          |Delhi    |\n",
            "|ORD020  |C010       |Electronics|Laptop      |54000 |2024-01-15|Completed|2024      |1          |Bangalore|\n",
            "|ORD019  |C009       |Electronics|Tablet      |29000 |2024-01-15|Completed|2024      |1          |Mumbai   |\n",
            "+--------+-----------+-----------+------------+------+----------+---------+----------+-----------+---------+\n",
            "\n",
            "Validation — missing columns: []\n",
            "Validation — mismatched types (read vs expected): {}\n",
            "\n",
            " ORC schemas:\n",
            "revenue_by_city:\n",
            "root\n",
            " |-- city: string (nullable = true)\n",
            " |-- total_revenue: long (nullable = true)\n",
            "\n",
            "revenue_by_category:\n",
            "root\n",
            " |-- category: string (nullable = true)\n",
            " |-- total_revenue: long (nullable = true)\n",
            "\n",
            "revenue_by_product:\n",
            "root\n",
            " |-- product: string (nullable = true)\n",
            " |-- total_revenue: long (nullable = true)\n",
            "\n",
            "aov_by_city:\n",
            "root\n",
            " |-- city: string (nullable = true)\n",
            " |-- avg_order_value: double (nullable = true)\n",
            " |-- order_count: long (nullable = true)\n",
            "\n",
            "top3_products_by_revenue:\n",
            "root\n",
            " |-- product: string (nullable = true)\n",
            " |-- total_revenue: long (nullable = true)\n",
            " |-- rank: integer (nullable = true)\n",
            "\n",
            "\n",
            "Row counts:\n",
            "revenue_by_city: 4\n",
            "revenue_by_category: 2\n",
            "revenue_by_product: 6\n",
            "aov_by_city: 4\n",
            "top3_products_by_revenue: 3\n",
            "+---------+-------------+\n",
            "|city     |total_revenue|\n",
            "+---------+-------------+\n",
            "|Bangalore|217000       |\n",
            "|Delhi    |187000       |\n",
            "|Mumbai   |185000       |\n",
            "|Chennai  |62000        |\n",
            "+---------+-------------+\n",
            "\n",
            "+-----------+-------------+\n",
            "|category   |total_revenue|\n",
            "+-----------+-------------+\n",
            "|Electronics|464000       |\n",
            "|Home       |187000       |\n",
            "+-----------+-------------+\n",
            "\n",
            "+------------+-------------+\n",
            "|product     |total_revenue|\n",
            "+------------+-------------+\n",
            "|Laptop      |314000       |\n",
            "|Vacuum      |88000        |\n",
            "|Tablet      |85000        |\n",
            "|Air Purifier|78000        |\n",
            "|Mobile      |65000        |\n",
            "|Mixer       |21000        |\n",
            "+------------+-------------+\n",
            "\n",
            "+---------+------------------+-----------+\n",
            "|city     |avg_order_value   |order_count|\n",
            "+---------+------------------+-----------+\n",
            "|Chennai  |62000.0           |1          |\n",
            "|Delhi    |37400.0           |5          |\n",
            "|Mumbai   |37000.0           |5          |\n",
            "|Bangalore|36166.666666666664|6          |\n",
            "+---------+------------------+-----------+\n",
            "\n",
            "+-------+-------------+----+\n",
            "|product|total_revenue|rank|\n",
            "+-------+-------------+----+\n",
            "|Laptop |314000       |1   |\n",
            "|Vacuum |88000        |2   |\n",
            "|Tablet |85000        |3   |\n",
            "+-------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 29\n",
        "df = df.filter(df.amount > 30000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "yItUh_lQqCtP",
        "outputId": "7f35284a-464d-4f61-e37c-f043955a217e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"ts\": \"2025-12-24 04:40:13.960\", \"level\": \"ERROR\", \"logger\": \"DataFrameQueryContextLogger\", \"msg\": \"[CAST_INVALID_INPUT] The value '' of the type \\\"STRING\\\" cannot be cast to \\\"BIGINT\\\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\", \"context\": {\"file\": \"line 2 in cell [45]\", \"line\": \"\", \"fragment\": \"__gt__\", \"errorClass\": \"CAST_INVALID_INPUT\"}, \"exception\": {\"class\": \"Py4JJavaError\", \"msg\": \"An error occurred while calling o930.showString.\\n: org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value '' of the type \\\"STRING\\\" cannot be cast to \\\"BIGINT\\\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\\n== DataFrame ==\\n\\\"__gt__\\\" was called from\\nline 2 in cell [45]\\n\\n\\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toLongExact(UTF8StringUtils.scala:31)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toLongExact(UTF8StringUtils.scala)\\n\\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\\n\\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\\n\\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\\n\\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\\n\\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:544)\\n\\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:497)\\n\\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:58)\\n\\tat org.apache.spark.sql.classic.Dataset.collectFromPlan(Dataset.scala:2244)\\n\\tat org.apache.spark.sql.classic.Dataset.$anonfun$head$1(Dataset.scala:1379)\\n\\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$2(Dataset.scala:2234)\\n\\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\\n\\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$1(Dataset.scala:2232)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\\n\\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\\n\\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\\n\\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\\n\\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\\n\\tat org.apache.spark.sql.classic.Dataset.withAction(Dataset.scala:2232)\\n\\tat org.apache.spark.sql.classic.Dataset.head(Dataset.scala:1379)\\n\\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2810)\\n\\tat org.apache.spark.sql.classic.Dataset.getRows(Dataset.scala:339)\\n\\tat org.apache.spark.sql.classic.Dataset.showString(Dataset.scala:375)\\n\\tat jdk.internal.reflect.GeneratedMethodAccessor96.invoke(Unknown Source)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\\n\\tat py4j.Gateway.invoke(Gateway.java:282)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\\n\\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\", \"stacktrace\": [{\"class\": null, \"method\": \"deco\", \"file\": \"/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\", \"line\": \"282\"}, {\"class\": null, \"method\": \"get_return_value\", \"file\": \"/usr/local/lib/python3.12/dist-packages/py4j/protocol.py\", \"line\": \"327\"}]}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NumberFormatException",
          "evalue": "[CAST_INVALID_INPUT] The value '' of the type \"STRING\" cannot be cast to \"BIGINT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n== DataFrame ==\n\"__gt__\" was called from\nline 2 in cell [45]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNumberFormatException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2291519656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#task 29\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamount\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     def _show_string(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py\u001b[0m in \u001b[0;36m_show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNumberFormatException\u001b[0m: [CAST_INVALID_INPUT] The value '' of the type \"STRING\" cannot be cast to \"BIGINT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n== DataFrame ==\n\"__gt__\" was called from\nline 2 in cell [45]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Correct: keep filtered DataFrame in a variable, then call show()\n",
        "raw_df = raw_df.filter(col(\"amount\") > 30000)\n",
        "raw_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "jNEYPagAqHzM",
        "outputId": "8a4e90c3-717e-4f33-ca46-525da16bafae"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{\"ts\": \"2025-12-24 04:43:11.830\", \"level\": \"ERROR\", \"logger\": \"DataFrameQueryContextLogger\", \"msg\": \"[CAST_INVALID_INPUT] The value '' of the type \\\"STRING\\\" cannot be cast to \\\"BIGINT\\\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\", \"context\": {\"file\": \"line 4 in cell [52]\", \"line\": \"\", \"fragment\": \"__gt__\", \"errorClass\": \"CAST_INVALID_INPUT\"}, \"exception\": {\"class\": \"Py4JJavaError\", \"msg\": \"An error occurred while calling o1038.showString.\\n: org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value '' of the type \\\"STRING\\\" cannot be cast to \\\"BIGINT\\\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\\n== DataFrame ==\\n\\\"__gt__\\\" was called from\\nline 4 in cell [52]\\n\\n\\tat org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:145)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.withException(UTF8StringUtils.scala:51)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils$.toLongExact(UTF8StringUtils.scala:31)\\n\\tat org.apache.spark.sql.catalyst.util.UTF8StringUtils.toLongExact(UTF8StringUtils.scala)\\n\\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\\n\\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\\n\\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\\n\\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)\\n\\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\\n\\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\\n\\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\\n\\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\\n\\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\\n\\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\\n\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\\n\\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:544)\\n\\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:497)\\n\\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:58)\\n\\tat org.apache.spark.sql.classic.Dataset.collectFromPlan(Dataset.scala:2244)\\n\\tat org.apache.spark.sql.classic.Dataset.$anonfun$head$1(Dataset.scala:1379)\\n\\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$2(Dataset.scala:2234)\\n\\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\\n\\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$1(Dataset.scala:2232)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\\n\\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\\n\\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\\n\\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)\\n\\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\\n\\tat org.apache.spark.sql.classic.Dataset.withAction(Dataset.scala:2232)\\n\\tat org.apache.spark.sql.classic.Dataset.head(Dataset.scala:1379)\\n\\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2810)\\n\\tat org.apache.spark.sql.classic.Dataset.getRows(Dataset.scala:339)\\n\\tat org.apache.spark.sql.classic.Dataset.showString(Dataset.scala:375)\\n\\tat jdk.internal.reflect.GeneratedMethodAccessor96.invoke(Unknown Source)\\n\\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\\n\\tat py4j.Gateway.invoke(Gateway.java:282)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\\n\\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\\n\\tat java.base/java.lang.Thread.run(Thread.java:840)\\n\", \"stacktrace\": [{\"class\": null, \"method\": \"deco\", \"file\": \"/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\", \"line\": \"282\"}, {\"class\": null, \"method\": \"get_return_value\", \"file\": \"/usr/local/lib/python3.12/dist-packages/py4j/protocol.py\", \"line\": \"327\"}]}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NumberFormatException",
          "evalue": "[CAST_INVALID_INPUT] The value '' of the type \"STRING\" cannot be cast to \"BIGINT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n== DataFrame ==\n\"__gt__\" was called from\nline 4 in cell [52]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNumberFormatException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2961978193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Correct: keep filtered DataFrame in a variable, then call show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mraw_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"amount\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mraw_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     def _show_string(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py\u001b[0m in \u001b[0;36m_show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNumberFormatException\u001b[0m: [CAST_INVALID_INPUT] The value '' of the type \"STRING\" cannot be cast to \"BIGINT\" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018\n== DataFrame ==\n\"__gt__\" was called from\nline 4 in cell [52]\n"
          ]
        }
      ]
    }
  ]
}