{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-JDkl5tI1nrP"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession, functions as F, types as T, Window\n",
        "\n",
        "spark = SparkSession.builder.appName(\"OnlineOrdersPipeline\").config(\"spark.sql.shuffle.partitions\",\"8\").getOrCreate()\n",
        "\n",
        "orders_data = [\n",
        "(\"O001\",\"Delhi \",\"Laptop\",\"45000\",\"2024-01-05\",\"Completed\"),\n",
        "(\"O002\",\"Mumbai\",\"Mobile \",\"32000\",\"05/01/2024\",\"Completed\"),\n",
        "(\"O003\",\"Bangalore\",\"Tablet\",\"30000\",\"2024/01/06\",\"Completed\"),\n",
        "(\"O004\",\"Delhi\",\"Laptop\",\"\",\"2024-01-07\",\"Cancelled\"),\n",
        "(\"O005\",\"Mumbai\",\"Mobile\",\"invalid\",\"2024-01-08\",\"Completed\"),\n",
        "(\"O006\",\"Chennai\",\"Tablet\",None,\"2024-01-08\",\"Completed\"),\n",
        "(\"O007\",\"Delhi\",\"Laptop\",\"47000\",\"09-01-2024\",\"Completed\"),\n",
        "(\"O008\",\"Bangalore\",\"Mobile\",\"28000\",\"2024-01-09\",\"Completed\"),\n",
        "(\"O009\",\"Mumbai\",\"Laptop\",\"55000\",\"2024-01-10\",\"Completed\"),\n",
        "(\"O009\",\"Mumbai\",\"Laptop\",\"55000\",\"2024-01-10\",\"Completed\")\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK1\n",
        "orders_schema = T.StructType([\n",
        "    T.StructField(\"order_id\",  T.StringType(), True),\n",
        "    T.StructField(\"city\",      T.StringType(), True),\n",
        "    T.StructField(\"product\",   T.StringType(), True),\n",
        "    T.StructField(\"amount\",    T.StringType(), True),\n",
        "    T.StructField(\"order_date\",T.StringType(), True),\n",
        "    T.StructField(\"status\",    T.StringType(), True),\n",
        "])\n"
      ],
      "metadata": {
        "id": "9F6CCkZ-14Ku"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK2\n",
        "orders_raw = spark.createDataFrame(orders_data, orders_schema)"
      ],
      "metadata": {
        "id": "_CzsUxuP2EwY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK3\n",
        "orders_raw.printSchema()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rbMsJUdp2Es4",
        "outputId": "3159775d-45c9-4781-a5b8-ead8f7bf8165"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: string (nullable = true)\n",
            " |-- order_date: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PHASE 2"
      ],
      "metadata": {
        "id": "Pa0fjJwF2iMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK4 &TASK5\n",
        "trim_norm = lambda c: F.upper(F.trim(F.regexp_replace(F.col(c), r\"\\s+\", \" \")))\n",
        "orders_t4 = (orders_raw\n",
        "             .withColumn(\"order_id\", trim_norm(\"order_id\"))\n",
        "             .withColumn(\"city\",     trim_norm(\"city\"))\n",
        "             .withColumn(\"product\",  trim_norm(\"product\"))\n",
        "             .withColumn(\"status\",   trim_norm(\"status\")))\n"
      ],
      "metadata": {
        "id": "8__mGiB42EqM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK6\n",
        "to_amount_int = lambda c: F.when(F.trim(F.col(c)).rlike(r\"^\\d+$\"), F.trim(F.col(c)).cast(\"int\")).otherwise(F.lit(None).cast(\"int\"))\n",
        "orders_t6 = orders_t4.withColumn(\"amount_int\", to_amount_int(\"amount\"))\n"
      ],
      "metadata": {
        "id": "B3G0KMHC2End"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK7\n",
        "orders_t7 = orders_t6.withColumn(\"amount_invalid\", F.col(\"amount_int\").isNull())\n",
        "\n"
      ],
      "metadata": {
        "id": "7voy9XRR2Ek9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "orders_dedup_exact = orders_t8.dropDuplicates()"
      ],
      "metadata": {
        "id": "5UliY5Nq2EcU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df=df.filter(F.col(\"status\")==\"Completed\")\n",
        "#9\n",
        "df = spark.createDataFrame(orders_data, orders_schema)\n",
        "df_completed = df.filter(F.upper(F.trim(F.col(\"status\"))).like(\"COMP%\"))\n",
        "\n",
        "df_completed.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6Ijz4BrI5fSK",
        "outputId": "94b0ba36-580d-4084-9723-99cd16505e4c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-------+-------+----------+---------+\n",
            "|order_id|city     |product|amount |order_date|status   |\n",
            "+--------+---------+-------+-------+----------+---------+\n",
            "|O001    |Delhi    |Laptop |45000  |2024-01-05|Completed|\n",
            "|O002    |Mumbai   |Mobile |32000  |05/01/2024|Completed|\n",
            "|O003    |Bangalore|Tablet |30000  |2024/01/06|Completed|\n",
            "|O005    |Mumbai   |Mobile |invalid|2024-01-08|Completed|\n",
            "|O006    |Chennai  |Tablet |NULL   |2024-01-08|Completed|\n",
            "|O007    |Delhi    |Laptop |47000  |09-01-2024|Completed|\n",
            "|O008    |Bangalore|Mobile |28000  |2024-01-09|Completed|\n",
            "|O009    |Mumbai   |Laptop |55000  |2024-01-10|Completed|\n",
            "|O009    |Mumbai   |Laptop |55000  |2024-01-10|Completed|\n",
            "+--------+---------+-------+-------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK 10,TASK 11,TASK12\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "amount_int = F.when(F.trim(F.col(\"amount\")).rlike(r\"^\\d+$\"), F.trim(F.col(\"amount\")).cast(\"int\"))\n",
        "\n",
        "clean_view = (\n",
        "    orders_raw\n",
        "    .withColumn(\"amount_int\", amount_int)\n",
        "    .withColumn(\"status_norm\", F.upper(F.trim(F.col(\"status\"))))\n",
        "    .withColumn(\"city_norm\",   F.upper(F.trim(F.col(\"city\"))))\n",
        "    .withColumn(\"product_norm\",F.upper(F.trim(F.col(\"product\"))))\n",
        "    .filter(F.col(\"status_norm\").like(\"COMP%\"))\n",
        "    .filter(F.col(\"amount_int\").isNotNull())\n",
        ")\n",
        "\n",
        "print(\"Total revenue per city:\")\n",
        "clean_view.groupBy(\"city_norm\").agg(F.sum(\"amount_int\").alias(\"total_revenue\")).show()\n",
        "\n",
        "print(\"Total revenue per product:\")\n",
        "clean_view.groupBy(\"product_norm\").agg(F.sum(\"amount_int\").alias(\"total_revenue\")).show()\n",
        "\n",
        "print(\"Average order value per city:\")\n",
        "clean_view.groupBy(\"city_norm\").agg(F.avg(\"amount_int\").alias(\"avg_order_value\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9WjNnOVx7oSy",
        "outputId": "cab96fd8-b538-4150-d1db-ffd080892ac6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total revenue per city:\n",
            "+---------+-------------+\n",
            "|city_norm|total_revenue|\n",
            "+---------+-------------+\n",
            "|    DELHI|        92000|\n",
            "|BANGALORE|        58000|\n",
            "|   MUMBAI|       142000|\n",
            "+---------+-------------+\n",
            "\n",
            "Total revenue per product:\n",
            "+------------+-------------+\n",
            "|product_norm|total_revenue|\n",
            "+------------+-------------+\n",
            "|      LAPTOP|       202000|\n",
            "|      MOBILE|        60000|\n",
            "|      TABLET|        30000|\n",
            "+------------+-------------+\n",
            "\n",
            "Average order value per city:\n",
            "+---------+------------------+\n",
            "|city_norm|   avg_order_value|\n",
            "+---------+------------------+\n",
            "|    DELHI|           46000.0|\n",
            "|BANGALORE|           29000.0|\n",
            "|   MUMBAI|47333.333333333336|\n",
            "+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK 13,TASK 14\n",
        "from pyspark.sql import functions as F, Window\n",
        "\n",
        "df_clean = (df\n",
        "    .withColumn(\"amount_int\", F.when(F.col(\"amount\").rlike(r\"^\\d+$\"), F.col(\"amount\").cast(\"int\")))\n",
        "    .filter(F.upper(F.col(\"status\")).like(\"COMP%\"))\n",
        "    .filter(F.col(\"amount_int\").isNotNull())\n",
        ")\n",
        "\n",
        "rev_city = df_clean.groupBy(\"city\").agg(F.sum(\"amount_int\").alias(\"total_revenue\"))\n",
        "\n",
        "w = Window.orderBy(F.col(\"total_revenue\").desc())\n",
        "ranked_cities = rev_city.withColumn(\"rank\", F.dense_rank().over(w))\n",
        "\n",
        "print(\"Rank cities by total revenue:\")\n",
        "ranked_cities.show()\n",
        "\n",
        "print(\"Top-performing city:\")\n",
        "ranked_cities.filter(F.col(\"rank\")==1).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MoT5NxgJ6kwC",
        "outputId": "a037effa-459a-4207-a91e-17c668dc3783"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank cities by total revenue:\n",
            "+---------+-------------+----+\n",
            "|     city|total_revenue|rank|\n",
            "+---------+-------------+----+\n",
            "|   Mumbai|       142000|   1|\n",
            "|Bangalore|        58000|   2|\n",
            "|    Delhi|        47000|   3|\n",
            "|   Delhi |        45000|   4|\n",
            "+---------+-------------+----+\n",
            "\n",
            "Top-performing city:\n",
            "+------+-------------+----+\n",
            "|  city|total_revenue|rank|\n",
            "+------+-------------+----+\n",
            "|Mumbai|       142000|   1|\n",
            "+------+-------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK 15\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "df_cached = df_clean.cache()\n",
        "print(\"Rows after cache materialization:\", df_cached.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XVI5fW3K6ktP",
        "outputId": "4381dbb9-0f5c-43ec-e735-a24b666a0a44"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows after cache materialization: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK16\n",
        "rev_city = df_cached.groupBy(\"city\").agg(F.sum(\"amount_int\").alias(\"total_revenue\"))\n",
        "rev_city.show()\n",
        "\n",
        "rev_product = df_cached.groupBy(\"product\").agg(F.sum(\"amount_int\").alias(\"total_revenue\"))\n",
        "rev_product.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BlilEFNN6kqh",
        "outputId": "6253557d-b13c-42e9-8254-4f3d94e0f14e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|     city|total_revenue|\n",
            "+---------+-------------+\n",
            "|Bangalore|        58000|\n",
            "|   Delhi |        45000|\n",
            "|   Mumbai|       142000|\n",
            "|    Delhi|        47000|\n",
            "+---------+-------------+\n",
            "\n",
            "+-------+-------------+\n",
            "|product|total_revenue|\n",
            "+-------+-------------+\n",
            "| Laptop|       202000|\n",
            "| Tablet|        30000|\n",
            "|Mobile |        32000|\n",
            "| Mobile|        28000|\n",
            "+-------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TASK 17\n",
        "\n",
        "print(\"\\n== Plan: df_cached ==\")\n",
        "df_cached.explain(True)\n",
        "\n",
        "print(\"\\n== Plan: rev_city ==\")\n",
        "rev_city.explain(True)\n",
        "\n",
        "print(\"\\n== Plan: rev_product ==\")\n",
        "rev_product.explain(True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cnBqZdDS6kny",
        "outputId": "d495aa9e-b081-414a-b60a-0fc08e8809b3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Plan: df_cached ==\n",
            "== Parsed Logical Plan ==\n",
            "'Filter 'isNotNull('amount_int)\n",
            "+- Filter upper(status#68) LIKE COMP%\n",
            "   +- Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "      +- LogicalRDD [order_id#63, city#64, product#65, amount#66, order_date#67, status#68], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, city: string, product: string, amount: string, order_date: string, status: string, amount_int: int\n",
            "Filter isnotnull(amount_int#161)\n",
            "+- Filter upper(status#68) LIKE COMP%\n",
            "   +- Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "      +- LogicalRDD [order_id#63, city#64, product#65, amount#66, order_date#67, status#68], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "InMemoryRelation [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, amount_int#161], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "   +- *(1) Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "      +- *(1) Filter (isnotnull(status#68) AND (StartsWith(upper(status#68), COMP) AND CASE WHEN RLIKE(amount#66, ^\\d+$) THEN isnotnull(cast(amount#66 as int)) ELSE false END))\n",
            "         +- *(1) Scan ExistingRDD[order_id#63,city#64,product#65,amount#66,order_date#67,status#68]\n",
            "\n",
            "== Physical Plan ==\n",
            "InMemoryTableScan [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, amount_int#161]\n",
            "   +- InMemoryRelation [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, amount_int#161], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "         +- *(1) Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "            +- *(1) Filter (isnotnull(status#68) AND (StartsWith(upper(status#68), COMP) AND CASE WHEN RLIKE(amount#66, ^\\d+$) THEN isnotnull(cast(amount#66 as int)) ELSE false END))\n",
            "               +- *(1) Scan ExistingRDD[order_id#63,city#64,product#65,amount#66,order_date#67,status#68]\n",
            "\n",
            "\n",
            "== Plan: rev_city ==\n",
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['city], ['city, 'sum('amount_int) AS total_revenue#631]\n",
            "+- Filter isnotnull(amount_int#161)\n",
            "   +- Filter upper(status#68) LIKE COMP%\n",
            "      +- Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "         +- LogicalRDD [order_id#63, city#64, product#65, amount#66, order_date#67, status#68], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, total_revenue: bigint\n",
            "Aggregate [city#64], [city#64, sum(amount_int#161) AS total_revenue#631L]\n",
            "+- Filter isnotnull(amount_int#161)\n",
            "   +- Filter upper(status#68) LIKE COMP%\n",
            "      +- Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "         +- LogicalRDD [order_id#63, city#64, product#65, amount#66, order_date#67, status#68], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [city#64], [city#64, sum(amount_int#161) AS total_revenue#631L]\n",
            "+- Project [city#64, amount_int#161]\n",
            "   +- InMemoryRelation [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, amount_int#161], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "         +- *(1) Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "            +- *(1) Filter (isnotnull(status#68) AND (StartsWith(upper(status#68), COMP) AND CASE WHEN RLIKE(amount#66, ^\\d+$) THEN isnotnull(cast(amount#66 as int)) ELSE false END))\n",
            "               +- *(1) Scan ExistingRDD[order_id#63,city#64,product#65,amount#66,order_date#67,status#68]\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[city#64], functions=[sum(amount_int#161)], output=[city#64, total_revenue#631L])\n",
            "   +- Exchange hashpartitioning(city#64, 8), ENSURE_REQUIREMENTS, [plan_id=700]\n",
            "      +- HashAggregate(keys=[city#64], functions=[partial_sum(amount_int#161)], output=[city#64, sum#748L])\n",
            "         +- InMemoryTableScan [city#64, amount_int#161]\n",
            "               +- InMemoryRelation [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, amount_int#161], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                     +- *(1) Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "                        +- *(1) Filter (isnotnull(status#68) AND (StartsWith(upper(status#68), COMP) AND CASE WHEN RLIKE(amount#66, ^\\d+$) THEN isnotnull(cast(amount#66 as int)) ELSE false END))\n",
            "                           +- *(1) Scan ExistingRDD[order_id#63,city#64,product#65,amount#66,order_date#67,status#68]\n",
            "\n",
            "\n",
            "== Plan: rev_product ==\n",
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['product], ['product, 'sum('amount_int) AS total_revenue#827]\n",
            "+- Filter isnotnull(amount_int#161)\n",
            "   +- Filter upper(status#68) LIKE COMP%\n",
            "      +- Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "         +- LogicalRDD [order_id#63, city#64, product#65, amount#66, order_date#67, status#68], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "product: string, total_revenue: bigint\n",
            "Aggregate [product#65], [product#65, sum(amount_int#161) AS total_revenue#827L]\n",
            "+- Filter isnotnull(amount_int#161)\n",
            "   +- Filter upper(status#68) LIKE COMP%\n",
            "      +- Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "         +- LogicalRDD [order_id#63, city#64, product#65, amount#66, order_date#67, status#68], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [product#65], [product#65, sum(amount_int#161) AS total_revenue#827L]\n",
            "+- Project [product#65, amount_int#161]\n",
            "   +- InMemoryRelation [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, amount_int#161], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "         +- *(1) Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "            +- *(1) Filter (isnotnull(status#68) AND (StartsWith(upper(status#68), COMP) AND CASE WHEN RLIKE(amount#66, ^\\d+$) THEN isnotnull(cast(amount#66 as int)) ELSE false END))\n",
            "               +- *(1) Scan ExistingRDD[order_id#63,city#64,product#65,amount#66,order_date#67,status#68]\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[product#65], functions=[sum(amount_int#161)], output=[product#65, total_revenue#827L])\n",
            "   +- Exchange hashpartitioning(product#65, 8), ENSURE_REQUIREMENTS, [plan_id=713]\n",
            "      +- HashAggregate(keys=[product#65], functions=[partial_sum(amount_int#161)], output=[product#65, sum#944L])\n",
            "         +- InMemoryTableScan [product#65, amount_int#161]\n",
            "               +- InMemoryRelation [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, amount_int#161], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                     +- *(1) Project [order_id#63, city#64, product#65, amount#66, order_date#67, status#68, CASE WHEN RLIKE(amount#66, ^\\d+$) THEN cast(amount#66 as int) END AS amount_int#161]\n",
            "                        +- *(1) Filter (isnotnull(status#68) AND (StartsWith(upper(status#68), COMP) AND CASE WHEN RLIKE(amount#66, ^\\d+$) THEN isnotnull(cast(amount#66 as int)) ELSE false END))\n",
            "                           +- *(1) Scan ExistingRDD[order_id#63,city#64,product#65,amount#66,order_date#67,status#68]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04Gv4a2u6klK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "povhUDsJ6kia"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}